{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"news-recap","text":"<p><code>news-recap</code> is a CLI-first system for:</p> <ul> <li>collecting news from RSS/Atom feeds,</li> <li>normalizing and cleaning article text,</li> <li>semantic deduplication and clustering,</li> <li>running queue-based LLM tasks,</li> <li>generating story/highlights/Q&amp;A outputs,</li> <li>tracking read-state and feedback,</li> <li>storing history and artifacts in SQLite.</li> </ul>"},{"location":"#current-scope","title":"Current Scope","text":"<ul> <li>Source ingestion from RSS/Atom feeds (including Inoreader Output RSS).</li> <li>Shared article storage with user-scoped retrieval.</li> <li>Queue worker runtime for external CLI agents.</li> <li>Story assignment, highlights generation, monitor answers, ad-hoc QA.</li> <li>Domain output persistence and observability commands.</li> </ul>"},{"location":"#where-to-start","title":"Where To Start","text":"<ul> <li>Installation and environment setup: <code>installation.md</code></li> <li>Full CLI commands and examples: <code>cli.md</code></li> </ul>"},{"location":"#advanced","title":"Advanced","text":"<p>Use:</p> <pre><code>news-recap --help\n</code></pre> <p>for the complete command tree.</p>"},{"location":"cli/","title":"CLI","text":"<p><code>news-recap</code> is operated from CLI commands grouped by workflow stage.</p>"},{"location":"cli/#command-map","title":"Command Map","text":"<ul> <li><code>ingest</code>: source import, stats, dedup inspection, retention cleanup.</li> <li><code>llm</code>: task queue, worker runtime, retries, smoke checks, benchmark.</li> <li><code>stories</code>: pinned story definitions and daily story assignment build.</li> <li><code>highlights</code>: enqueue daily highlights generation.</li> <li><code>story-details</code>: enqueue detailed output for one story.</li> <li><code>monitors</code>: define/list/run scheduled monitor prompts.</li> <li><code>qa</code>: enqueue ad-hoc question answering tasks.</li> <li><code>read-state</code>: mark outputs/blocks as viewed/opened.</li> <li><code>feedback</code>: attach like/dislike/hide/pin feedback.</li> <li><code>insights</code>: domain-level stats and output listing.</li> </ul>"},{"location":"cli/#common-notes","title":"Common Notes","text":"<ul> <li>Most commands support <code>--db-path</code> to point to a specific SQLite file.</li> <li>Source IDs must use format <code>article:&lt;article_id&gt;</code>.</li> <li>Queue tasks are executed by <code>news-recap llm worker</code>.</li> </ul>"},{"location":"cli/#ingestion-commands","title":"Ingestion Commands","text":""},{"location":"cli/#ingest-daily","title":"<code>ingest daily</code>","text":"<p>Run one ingestion cycle from RSS/Atom feeds.</p> <pre><code>news-recap ingest daily\nnews-recap ingest daily --feed-url https://example.com/feed.xml\n</code></pre> <p>Key options: - <code>--feed-url</code> (repeatable) - <code>--db-path</code></p> <p>If <code>--feed-url</code> is omitted, feeds are loaded from: - <code>NEWS_RECAP_RSS_FEED_URLS</code> - <code>NEWS_RECAP_RSS_FEED_URL</code></p>"},{"location":"cli/#ingest-stats","title":"<code>ingest stats</code>","text":"<p>Show ingestion and dedup metrics in a rolling window.</p> <pre><code>news-recap ingest stats --hours 24 --recent-runs 5\n</code></pre> <p>Key options: - <code>--hours</code> - <code>--source</code> - <code>--recent-runs</code></p>"},{"location":"cli/#ingest-clusters","title":"<code>ingest clusters</code>","text":"<p>Inspect dedup cluster distribution for a run.</p> <pre><code>news-recap ingest clusters --hours 24 --limit 20\nnews-recap ingest clusters --run-id &lt;run_id&gt; --show-members\n</code></pre> <p>Key options: - <code>--run-id</code> or <code>--hours</code>/<code>--source</code> for run resolution - <code>--min-size</code> - <code>--members-per-cluster</code> - <code>--show-members</code></p>"},{"location":"cli/#ingest-duplicates","title":"<code>ingest duplicates</code>","text":"<p>Print duplicate cluster examples (cluster size &gt;= 2).</p> <pre><code>news-recap ingest duplicates --hours 24 --limit-clusters 10\n</code></pre> <p>Key options: - <code>--run-id</code> or <code>--hours</code>/<code>--source</code> - <code>--limit-clusters</code> - <code>--members-per-cluster</code></p>"},{"location":"cli/#ingest-prune","title":"<code>ingest prune</code>","text":"<p>Delete old user-article links by retention age (<code>discovered_at</code>).</p> <pre><code>news-recap ingest prune --days 30\nnews-recap ingest prune --days 30 --dry-run\n</code></pre> <p>Key options: - <code>--days</code> - <code>--dry-run/--no-dry-run</code></p>"},{"location":"cli/#ingest-gc","title":"<code>ingest gc</code>","text":"<p>Delete globally unreferenced shared records.</p> <pre><code>news-recap ingest gc\nnews-recap ingest gc --dry-run\n</code></pre> <p>Key options: - <code>--dry-run/--no-dry-run</code></p>"},{"location":"cli/#llm-queue-commands","title":"LLM Queue Commands","text":""},{"location":"cli/#llm-enqueue-test","title":"<code>llm enqueue-test</code>","text":"<p>Enqueue one queue task with optional routing overrides.</p> <pre><code>news-recap llm enqueue-test --task-type highlights --prompt \"Top updates\"\n</code></pre> <p>Key options: - <code>--task-type</code> - <code>--prompt</code> - <code>--source-id</code> (repeatable) - <code>--priority</code> - <code>--agent</code>, <code>--model-profile</code>, <code>--model</code> - <code>--max-attempts</code>, <code>--timeout-seconds</code></p>"},{"location":"cli/#llm-worker","title":"<code>llm worker</code>","text":"<p>Run queue worker once or in loop mode.</p> <pre><code>news-recap llm worker --once\nnews-recap llm worker --loop --max-tasks 100\n</code></pre>"},{"location":"cli/#llm-stats","title":"<code>llm stats</code>","text":"<p>Show queue health, validation/retry metrics, and latency.</p> <pre><code>news-recap llm stats --hours 24\n</code></pre>"},{"location":"cli/#llm-failures","title":"<code>llm failures</code>","text":"<p>List failed attempts with sanitized diagnostics.</p> <pre><code>news-recap llm failures --hours 24\nnews-recap llm failures --failure-class output_invalid_json --agent codex\n</code></pre> <p>Key options: - <code>--hours</code> - <code>--task-type</code> - <code>--agent</code> - <code>--model</code> - <code>--failure-class</code> - <code>--limit</code></p>"},{"location":"cli/#llm-usage","title":"<code>llm usage</code>","text":"<p>Show per-attempt usage telemetry for one task.</p> <pre><code>news-recap llm usage --task-id &lt;task_id&gt;\n</code></pre>"},{"location":"cli/#llm-cost","title":"<code>llm cost</code>","text":"<p>Show grouped token/cost summary for recent attempts.</p> <pre><code>news-recap llm cost --hours 24 --group-by model\nnews-recap llm cost --hours 24 --group-by agent\n</code></pre>"},{"location":"cli/#llm-benchmark","title":"<code>llm benchmark</code>","text":"<p>Run deterministic queue benchmark and write report.</p> <pre><code>news-recap llm benchmark --tasks-per-type 10\nnews-recap llm benchmark --task-type highlights --task-type qa --use-configured-agent\n</code></pre> <p>Key options: - <code>--task-type</code> (repeatable) - <code>--tasks-per-type</code> - <code>--source-id</code> (repeatable) - <code>--output</code> - <code>--use-benchmark-agent/--use-configured-agent</code></p>"},{"location":"cli/#llm-tasks","title":"<code>llm tasks</code>","text":"<p>List recent tasks, optionally filtered by status.</p> <pre><code>news-recap llm tasks --status queued --limit 50\n</code></pre>"},{"location":"cli/#llm-inspect","title":"<code>llm inspect</code>","text":"<p>Show one task with event timeline.</p> <pre><code>news-recap llm inspect --task-id &lt;task_id&gt;\n</code></pre>"},{"location":"cli/#llm-retry","title":"<code>llm retry</code>","text":"<p>Manually re-queue failed/timeout/canceled task.</p> <pre><code>news-recap llm retry --task-id &lt;task_id&gt;\n</code></pre>"},{"location":"cli/#llm-cancel","title":"<code>llm cancel</code>","text":"<p>Cancel queued/running task.</p> <pre><code>news-recap llm cancel --task-id &lt;task_id&gt;\n</code></pre>"},{"location":"cli/#llm-smoke","title":"<code>llm smoke</code>","text":"<p>Run direct agent smoke checks without DB queue.</p> <pre><code>news-recap llm smoke\nnews-recap llm smoke --agent codex --model-profile quality\nnews-recap llm smoke --agent gemini --model gemini-2.5-flash\n</code></pre> <p>Key options: - <code>--agent</code> (repeatable) - <code>--model-profile</code> (<code>fast</code> or <code>quality</code>) - <code>--model</code> - <code>--prompt</code>, <code>--expect-substring</code>, <code>--timeout-seconds</code> - <code>--claude-command</code>, <code>--codex-command</code>, <code>--gemini-command</code></p>"},{"location":"cli/#story-and-output-generation-commands","title":"Story and Output Generation Commands","text":""},{"location":"cli/#stories-define","title":"<code>stories define</code>","text":"<p>Create or update a pinned story definition.</p> <pre><code>news-recap stories define --name \"Serbia updates\" --description \"Politics and economy\" --target-language sr\n</code></pre> <p>Key options: - <code>--story-id</code> (update existing) - <code>--name</code> - <code>--description</code> - <code>--target-language</code> - <code>--priority</code> - <code>--enabled/--disabled</code></p>"},{"location":"cli/#stories-list","title":"<code>stories list</code>","text":"<p>List pinned stories.</p> <pre><code>news-recap stories list\nnews-recap stories list --all\n</code></pre>"},{"location":"cli/#stories-build","title":"<code>stories build</code>","text":"<p>Build pinned + auto assignments for one business date.</p> <pre><code>news-recap stories build\nnews-recap stories build --date 2026-02-18\n</code></pre>"},{"location":"cli/#highlights-generate","title":"<code>highlights generate</code>","text":"<p>Enqueue highlights generation task for one date.</p> <pre><code>news-recap highlights generate --date 2026-02-18\n</code></pre> <p>Key options: - <code>--date</code> - <code>--priority</code> - <code>--agent</code>, <code>--model-profile</code>, <code>--model</code> - <code>--max-attempts</code>, <code>--timeout-seconds</code></p>"},{"location":"cli/#story-details-generate","title":"<code>story-details generate</code>","text":"<p>Enqueue detailed generation for one pinned story.</p> <pre><code>news-recap story-details generate --story-id &lt;story_id&gt; --date 2026-02-18\n</code></pre> <p>Key options: - <code>--story-id</code> - <code>--date</code> - routing/attempt/timeout options (same as highlights)</p>"},{"location":"cli/#monitor-and-qa-commands","title":"Monitor and Q&amp;A Commands","text":""},{"location":"cli/#monitors-define","title":"<code>monitors define</code>","text":"<p>Create or update monitor prompt.</p> <pre><code>news-recap monitors define --name \"Macro risks\" --prompt \"What changed in macro risk today?\"\n</code></pre> <p>Key options: - <code>--monitor-id</code> (update existing) - <code>--name</code> - <code>--prompt</code> - <code>--cadence</code> - <code>--enabled/--disabled</code></p>"},{"location":"cli/#monitors-list","title":"<code>monitors list</code>","text":"<p>List monitor definitions.</p> <pre><code>news-recap monitors list\nnews-recap monitors list --all\n</code></pre>"},{"location":"cli/#monitors-run","title":"<code>monitors run</code>","text":"<p>Enqueue monitor-answer tasks for enabled monitors.</p> <pre><code>news-recap monitors run --date 2026-02-18\n</code></pre> <p>Key options: - <code>--date</code> - routing/attempt/timeout options</p>"},{"location":"cli/#qa-ask","title":"<code>qa ask</code>","text":"<p>Enqueue ad-hoc QA task with bounded retrieval context.</p> <pre><code>news-recap qa ask --prompt \"What were the top geopolitical updates today?\"\nnews-recap qa ask --prompt \"What changed in energy markets?\" --lookback-days 7\n</code></pre> <p>Key options: - <code>--prompt</code> - <code>--lookback-days</code> - routing/attempt/timeout options</p>"},{"location":"cli/#read-state-and-feedback-commands","title":"Read-state and Feedback Commands","text":""},{"location":"cli/#read-state-mark","title":"<code>read-state mark</code>","text":"<p>Record read/open interaction for output or output block.</p> <pre><code>news-recap read-state mark --output-id &lt;output_id&gt; --event-type open\nnews-recap read-state mark --output-id &lt;output_id&gt; --event-type view --output-block-id 3\n</code></pre>"},{"location":"cli/#feedback-add","title":"<code>feedback add</code>","text":"<p>Attach feedback to output or one block.</p> <pre><code>news-recap feedback add --output-id &lt;output_id&gt; --feedback-type like\nnews-recap feedback add --output-id &lt;output_id&gt; --feedback-type hide --output-block-id 2\n</code></pre>"},{"location":"cli/#insights-commands","title":"Insights Commands","text":""},{"location":"cli/#insights-stats","title":"<code>insights stats</code>","text":"<p>Show domain counters for stories, outputs, and engagement.</p> <pre><code>news-recap insights stats --hours 24\n</code></pre>"},{"location":"cli/#insights-outputs","title":"<code>insights outputs</code>","text":"<p>List persisted business outputs.</p> <pre><code>news-recap insights outputs --limit 20\nnews-recap insights outputs --kind highlights --date 2026-02-18\n</code></pre>"},{"location":"cli/#important-environment-variables","title":"Important Environment Variables","text":"<ul> <li><code>NEWS_RECAP_DB_PATH</code></li> <li><code>NEWS_RECAP_RSS_FEED_URLS</code></li> <li><code>NEWS_RECAP_RSS_DEFAULT_ITEMS_PER_FEED</code></li> <li><code>NEWS_RECAP_RSS_FEED_ITEMS</code> (<code>&lt;feed_url&gt;|&lt;items&gt;,...</code>)</li> <li><code>NEWS_RECAP_ARTICLE_RETENTION_DAYS</code></li> <li><code>NEWS_RECAP_LLM_DEFAULT_AGENT</code></li> <li><code>NEWS_RECAP_LLM_TASK_TYPE_PROFILE_MAP</code></li> <li><code>NEWS_RECAP_LLM_CODEX_COMMAND_TEMPLATE</code></li> <li><code>NEWS_RECAP_LLM_CLAUDE_COMMAND_TEMPLATE</code></li> <li><code>NEWS_RECAP_LLM_GEMINI_COMMAND_TEMPLATE</code></li> <li><code>NEWS_RECAP_LLM_CODEX_MODEL_FAST</code> / <code>NEWS_RECAP_LLM_CODEX_MODEL_QUALITY</code></li> <li><code>NEWS_RECAP_LLM_CLAUDE_MODEL_FAST</code> / <code>NEWS_RECAP_LLM_CLAUDE_MODEL_QUALITY</code></li> <li><code>NEWS_RECAP_LLM_GEMINI_MODEL_FAST</code> / <code>NEWS_RECAP_LLM_GEMINI_MODEL_QUALITY</code></li> <li><code>NEWS_RECAP_LLM_PRICING</code> (<code>agent:model:input_per_1m:output_per_1m</code>, comma-separated)</li> <li><code>NEWS_RECAP_QA_LOOKBACK_DAYS</code></li> <li><code>NEWS_RECAP_RETRIEVAL_TOP_K</code></li> <li><code>NEWS_RECAP_RETRIEVAL_MAX_ARTICLES</code></li> <li><code>NEWS_RECAP_RETRIEVAL_TOKEN_BUDGET</code></li> <li><code>NEWS_RECAP_RETRIEVAL_CHAR_BUDGET</code></li> </ul>"},{"location":"cli/#help","title":"Help","text":"<pre><code>news-recap --help\nnews-recap ingest --help\nnews-recap llm --help\nnews-recap stories --help\nnews-recap highlights --help\nnews-recap story-details --help\nnews-recap monitors --help\nnews-recap qa --help\nnews-recap read-state --help\nnews-recap feedback --help\nnews-recap insights --help\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#installing-pipx","title":"Installing pipx","text":"<p><code>pipx</code> creates isolated environments to avoid conflicts with existing system packages.</p> MacOSLinuxWindows <p>In the terminal, execute: <pre><code>brew install pipx\npipx ensurepath\n</code></pre></p> <p>First, ensure Python is installed.</p> <p>Enter in the terminal:</p> <pre><code>python3 -m pip install --user pipx\npython3 -m pipx ensurepath\n</code></pre> <p>First, install Python if it's not already installed.</p> <p>In the command prompt, type (if Python was installed from the Microsoft Store, use <code>python3</code> instead of <code>python</code>):</p> <pre><code>python -m pip install --user pipx\n</code></pre>"},{"location":"installation/#installing-news-recap","title":"Installing <code>news-recap</code>:","text":"<p>In the terminal (command prompt), execute:</p> <pre><code>pipx install news-recap\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#news_recap","title":"news_recap","text":"<p>The file is mandatory for build system to find the package.</p>"},{"location":"reference/#news_recap-modules","title":"Modules","text":""},{"location":"reference/#news_recap.agent_runtime","title":"news_recap.agent_runtime","text":"<p>Shared Prefect tasks for running CLI LLM agents.</p> <p>Neutral module imported by both <code>recap/prefect_flow.py</code> (recap pipeline) and <code>brain/flows.py</code> (intelligence layer).</p>"},{"location":"reference/#news_recap.agent_runtime-attributes","title":"Attributes","text":""},{"location":"reference/#news_recap.agent_runtime.logger","title":"news_recap.agent_runtime.logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/#news_recap.agent_runtime-classes","title":"Classes","text":""},{"location":"reference/#news_recap.agent_runtime.AgentTaskResult","title":"news_recap.agent_runtime.AgentTaskResult  <code>dataclass</code>","text":"<p>Result of a generic agent task execution.</p> Attributes news_recap.agent_runtime.AgentTaskResult.agent <code>instance-attribute</code> <pre><code>agent: str\n</code></pre> <code></code> news_recap.agent_runtime.AgentTaskResult.elapsed_seconds <code>instance-attribute</code> <pre><code>elapsed_seconds: float\n</code></pre> <code></code> news_recap.agent_runtime.AgentTaskResult.model <code>instance-attribute</code> <pre><code>model: str\n</code></pre> <code></code> news_recap.agent_runtime.AgentTaskResult.output <code>instance-attribute</code> <pre><code>output: dict[str, Any]\n</code></pre> <code></code> news_recap.agent_runtime.AgentTaskResult.task_id <code>instance-attribute</code> <pre><code>task_id: str\n</code></pre>"},{"location":"reference/#news_recap.agent_runtime-functions","title":"Functions","text":""},{"location":"reference/#news_recap.agent_runtime.load_resources_step","title":"news_recap.agent_runtime.load_resources_step","text":"<pre><code>load_resources_step(*, entries: list[ArticleIndexEntry], resource_loader: ResourceLoader | None) -&gt; dict[str, bytes | str]\n</code></pre> <p>Load full article texts from URLs via <code>ResourceLoader</code>.</p>"},{"location":"reference/#news_recap.agent_runtime.read_task_output","title":"news_recap.agent_runtime.read_task_output","text":"<pre><code>read_task_output(workdir_root: Path, task_id: str) -&gt; dict[str, Any]\n</code></pre> <p>Read agent_result.json from a completed task workdir.</p>"},{"location":"reference/#news_recap.agent_runtime.run_agent_task","title":"news_recap.agent_runtime.run_agent_task","text":"<pre><code>run_agent_task(*, task_type: str, prompt: str, workdir_mgr: TaskWorkdirManager, routing_defaults: RoutingDefaults, article_entries: list[ArticleIndexEntry], agent_override: str | None = None, profile_override: str | None = None, model_override: str | None = None, metadata: dict[str, object] | None = None, continuity_summary: dict[str, object] | None = None, retrieval_context: dict[str, object] | None = None, story_context: dict[str, object] | None = None, timeout_seconds: int = 600) -&gt; AgentTaskResult\n</code></pre> <p>Execute one LLM task via CLI agent subprocess and return parsed output.</p> <p>Generic version used by intelligence flows (highlights, story details, monitors, Q&amp;A).  Materializes workdir, resolves routing, calls <code>CliAgentBackend</code> directly (no task-queue, no polling).</p>"},{"location":"reference/#news_recap.agent_runtime.task_results_dir","title":"news_recap.agent_runtime.task_results_dir","text":"<pre><code>task_results_dir(workdir_root: Path, task_id: str) -&gt; Path\n</code></pre> <p>Return the results subdirectory for a task.</p>"},{"location":"reference/#news_recap.brain","title":"news_recap.brain","text":"<p>LLM intelligence layer: file-based CLI agent execution via Prefect.</p> <p>Manages workdir materialisation, routing, contracts, and result persistence for CLI LLM agents (codex, claude, gemini).</p>"},{"location":"reference/#news_recap.brain-modules","title":"Modules","text":""},{"location":"reference/#news_recap.brain.backend","title":"news_recap.brain.backend","text":"<p>Orchestrator backend implementations.</p> Classes news_recap.brain.backend.BackendRunError <p>               Bases: <code>RuntimeError</code></p> <p>Backend execution error with retryability hint.</p> Attributes <code></code> news_recap.brain.backend.BackendRunError.transient <code>instance-attribute</code> <pre><code>transient = transient\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest <code>dataclass</code> <p>Inputs required to execute one task attempt.</p> Attributes <code></code> news_recap.brain.backend.BackendRunRequest.agent <code>instance-attribute</code> <pre><code>agent: str\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.command_template <code>instance-attribute</code> <pre><code>command_template: str\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.graceful_shutdown_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>graceful_shutdown_seconds: int | None = None\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.manifest_path <code>instance-attribute</code> <pre><code>manifest_path: Path\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.model <code>instance-attribute</code> <pre><code>model: str\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.profile <code>instance-attribute</code> <pre><code>profile: str\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.repair_mode <code>class-attribute</code> <code>instance-attribute</code> <pre><code>repair_mode: bool = False\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.shutdown_requested <code>class-attribute</code> <code>instance-attribute</code> <pre><code>shutdown_requested: Callable[[], bool] | None = None\n</code></pre> <code></code> news_recap.brain.backend.BackendRunRequest.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.backend.BackendRunResult <code>dataclass</code> <p>Execution outcome from backend runner.</p> Attributes <code></code> news_recap.brain.backend.BackendRunResult.exit_code <code>instance-attribute</code> <pre><code>exit_code: int\n</code></pre> <code></code> news_recap.brain.backend.BackendRunResult.stderr_path <code>instance-attribute</code> <pre><code>stderr_path: Path\n</code></pre> <code></code> news_recap.brain.backend.BackendRunResult.stdout_path <code>instance-attribute</code> <pre><code>stdout_path: Path\n</code></pre> <code></code> news_recap.brain.backend.BackendRunResult.timed_out <code>instance-attribute</code> <pre><code>timed_out: bool\n</code></pre> <code></code> news_recap.brain.backend.CliAgentBackend <p>Execute per-task CLI command template resolved by worker routing.</p> Functions <code></code> news_recap.brain.backend.CliAgentBackend.run <pre><code>run(request: BackendRunRequest) -&gt; BackendRunResult\n</code></pre> <code></code> news_recap.brain.backend.LlmBackend <p>               Bases: <code>Protocol</code></p> <p>Protocol implemented by backend runners.</p> Functions <code></code> news_recap.brain.backend.LlmBackend.run <pre><code>run(request: BackendRunRequest) -&gt; BackendRunResult\n</code></pre> <p>Run a task attempt and return execution metadata.</p> Modules <code></code> news_recap.brain.backend.base <p>Backend interface for orchestrator task execution.</p> Classes <code></code> news_recap.brain.backend.base.BackendRunRequest <code>dataclass</code> <p>Inputs required to execute one task attempt.</p> Attributes <code></code> news_recap.brain.backend.base.BackendRunRequest.agent <code>instance-attribute</code> <pre><code>agent: str\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.command_template <code>instance-attribute</code> <pre><code>command_template: str\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.graceful_shutdown_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>graceful_shutdown_seconds: int | None = None\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.manifest_path <code>instance-attribute</code> <pre><code>manifest_path: Path\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.model <code>instance-attribute</code> <pre><code>model: str\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.profile <code>instance-attribute</code> <pre><code>profile: str\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.repair_mode <code>class-attribute</code> <code>instance-attribute</code> <pre><code>repair_mode: bool = False\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.shutdown_requested <code>class-attribute</code> <code>instance-attribute</code> <pre><code>shutdown_requested: Callable[[], bool] | None = None\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunRequest.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunResult <code>dataclass</code> <p>Execution outcome from backend runner.</p> Attributes <code></code> news_recap.brain.backend.base.BackendRunResult.exit_code <code>instance-attribute</code> <pre><code>exit_code: int\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunResult.stderr_path <code>instance-attribute</code> <pre><code>stderr_path: Path\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunResult.stdout_path <code>instance-attribute</code> <pre><code>stdout_path: Path\n</code></pre> <code></code> news_recap.brain.backend.base.BackendRunResult.timed_out <code>instance-attribute</code> <pre><code>timed_out: bool\n</code></pre> <code></code> news_recap.brain.backend.base.LlmBackend <p>               Bases: <code>Protocol</code></p> <p>Protocol implemented by backend runners.</p> Functions <code></code> news_recap.brain.backend.base.LlmBackend.run <pre><code>run(request: BackendRunRequest) -&gt; BackendRunResult\n</code></pre> <p>Run a task attempt and return execution metadata.</p> <code></code> news_recap.brain.backend.benchmark_agent <p>Deterministic local agent for orchestrator benchmark matrix.</p> Classes Functions <code></code> news_recap.brain.backend.benchmark_agent.main <pre><code>main(argv: list[str] | None = None) -&gt; int\n</code></pre> <p>Run deterministic benchmark behavior based on task metadata.</p> <code></code> news_recap.brain.backend.cli_backend <p>Subprocess-based backend runner for CLI agents.</p> Classes <code></code> news_recap.brain.backend.cli_backend.BackendRunError <p>               Bases: <code>RuntimeError</code></p> <p>Backend execution error with retryability hint.</p> Attributes <code></code> news_recap.brain.backend.cli_backend.BackendRunError.transient <code>instance-attribute</code> <pre><code>transient = transient\n</code></pre> <code></code> news_recap.brain.backend.cli_backend.CliAgentBackend <p>Execute per-task CLI command template resolved by worker routing.</p> Functions <code></code> news_recap.brain.backend.cli_backend.CliAgentBackend.run <pre><code>run(request: BackendRunRequest) -&gt; BackendRunResult\n</code></pre> Functions <code></code> news_recap.brain.backend.echo_agent <p>Local demo agent for CLI backend integration tests.</p> Classes Functions <code></code> news_recap.brain.backend.echo_agent.main <pre><code>main(argv: list[str] | None = None) -&gt; int\n</code></pre> <p>Run local deterministic demo generation.</p>"},{"location":"reference/#news_recap.brain.contracts","title":"news_recap.brain.contracts","text":"<p>File-based contracts for orchestrator task inputs and outputs.</p> Classes news_recap.brain.contracts.AgentOutputBlock <code>dataclass</code> <p>One output block with mandatory source mapping.</p> Attributes <code></code> news_recap.brain.contracts.AgentOutputBlock.source_ids <code>instance-attribute</code> <pre><code>source_ids: list[str]\n</code></pre> <code></code> news_recap.brain.contracts.AgentOutputBlock.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> <code></code> news_recap.brain.contracts.AgentOutputContract <code>dataclass</code> <p>Top-level output payload produced by backend.</p> Attributes <code></code> news_recap.brain.contracts.AgentOutputContract.blocks <code>instance-attribute</code> <pre><code>blocks: list[AgentOutputBlock]\n</code></pre> <code></code> news_recap.brain.contracts.AgentOutputContract.metadata <code>class-attribute</code> <code>instance-attribute</code> <pre><code>metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.brain.contracts.ArticleIndexEntry <code>dataclass</code> <p>One allowed source entry for strict source mapping.</p> Attributes <code></code> news_recap.brain.contracts.ArticleIndexEntry.published_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>published_at: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.ArticleIndexEntry.source <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source: str = ''\n</code></pre> <code></code> news_recap.brain.contracts.ArticleIndexEntry.source_id <code>instance-attribute</code> <pre><code>source_id: str\n</code></pre> <code></code> news_recap.brain.contracts.ArticleIndexEntry.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.brain.contracts.ArticleIndexEntry.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskInputContract <code>dataclass</code> <p>Task input payload consumed by the backend.</p> Attributes <code></code> news_recap.brain.contracts.TaskInputContract.metadata <code>class-attribute</code> <code>instance-attribute</code> <pre><code>metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.brain.contracts.TaskInputContract.prompt <code>instance-attribute</code> <pre><code>prompt: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskInputContract.task_type <code>instance-attribute</code> <pre><code>task_type: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest <code>dataclass</code> <p>Manifest stored with each queued task.</p> Attributes <code></code> news_recap.brain.contracts.TaskManifest.articles_index_path <code>instance-attribute</code> <pre><code>articles_index_path: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.continuity_summary_path <code>class-attribute</code> <code>instance-attribute</code> <pre><code>continuity_summary_path: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.contract_version <code>instance-attribute</code> <pre><code>contract_version: int\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.input_resources_dir <code>class-attribute</code> <code>instance-attribute</code> <pre><code>input_resources_dir: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.output_result_path <code>instance-attribute</code> <pre><code>output_result_path: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.output_results_dir <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_results_dir: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.output_schema_hint <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_schema_hint: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.output_stderr_path <code>instance-attribute</code> <pre><code>output_stderr_path: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.output_stdout_path <code>instance-attribute</code> <pre><code>output_stdout_path: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.retrieval_context_path <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retrieval_context_path: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.story_context_path <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_context_path: str | None = None\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.task_id <code>instance-attribute</code> <pre><code>task_id: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.task_input_path <code>instance-attribute</code> <pre><code>task_input_path: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.task_type <code>instance-attribute</code> <pre><code>task_type: str\n</code></pre> <code></code> news_recap.brain.contracts.TaskManifest.workdir <code>instance-attribute</code> <pre><code>workdir: str\n</code></pre> Functions <code></code> news_recap.brain.contracts.load_json <pre><code>load_json(path: Path) -&gt; dict[str, Any]\n</code></pre> <p>Load JSON document and validate top-level object type.</p> <code></code> news_recap.brain.contracts.read_articles_index <pre><code>read_articles_index(path: Path) -&gt; list[ArticleIndexEntry]\n</code></pre> <p>Deserialize allowed articles index.</p> <code></code> news_recap.brain.contracts.read_manifest <pre><code>read_manifest(path: Path) -&gt; TaskManifest\n</code></pre> <p>Load and validate task manifest.</p> <code></code> news_recap.brain.contracts.read_task_input <pre><code>read_task_input(path: Path) -&gt; TaskInputContract\n</code></pre> <p>Deserialize and validate task input contract.</p> <code></code> news_recap.brain.contracts.write_agent_output <pre><code>write_agent_output(path: Path, payload: AgentOutputContract) -&gt; None\n</code></pre> <p>Serialize backend output contract.</p> <code></code> news_recap.brain.contracts.write_articles_index <pre><code>write_articles_index(path: Path, articles: list[ArticleIndexEntry]) -&gt; None\n</code></pre> <p>Serialize allowed articles index for strict source mapping.</p> <code></code> news_recap.brain.contracts.write_json <pre><code>write_json(path: Path, payload: dict[str, Any]) -&gt; None\n</code></pre> <p>Persist JSON payload using deterministic formatting.</p> <code></code> news_recap.brain.contracts.write_manifest <pre><code>write_manifest(path: Path, manifest: TaskManifest) -&gt; None\n</code></pre> <p>Persist task manifest.</p> <code></code> news_recap.brain.contracts.write_task_input <pre><code>write_task_input(path: Path, payload: TaskInputContract) -&gt; None\n</code></pre> <p>Serialize task input contract.</p>"},{"location":"reference/#news_recap.brain.flows","title":"news_recap.brain.flows","text":"<p>Intelligence flows: stories, highlights, monitors, and Q&amp;A.</p> <p>Each LLM operation runs synchronously via Prefect <code>@flow</code> / <code>@task</code>, calling CLI agents directly through <code>agent_runtime.run_agent_task</code>.</p> Attributes <code></code> news_recap.brain.flows.MIN_KEYWORD_TOKEN_LENGTH <code>module-attribute</code> <pre><code>MIN_KEYWORD_TOKEN_LENGTH = 4\n</code></pre> <code></code> news_recap.brain.flows.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.brain.flows.FeedbackAddCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.FeedbackAddCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.FeedbackAddCommand.feedback_type <code>instance-attribute</code> <pre><code>feedback_type: str\n</code></pre> <code></code> news_recap.brain.flows.FeedbackAddCommand.output_block_id <code>instance-attribute</code> <pre><code>output_block_id: int | None\n</code></pre> <code></code> news_recap.brain.flows.FeedbackAddCommand.output_id <code>instance-attribute</code> <pre><code>output_id: str\n</code></pre> <code></code> news_recap.brain.flows.FeedbackAddCommand.value <code>instance-attribute</code> <pre><code>value: str | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.HighlightsGenerateCommand.agent <code>instance-attribute</code> <pre><code>agent: str | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.business_date <code>instance-attribute</code> <pre><code>business_date: date | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.max_attempts <code>instance-attribute</code> <pre><code>max_attempts: int\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.model <code>instance-attribute</code> <pre><code>model: str | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.model_profile <code>instance-attribute</code> <pre><code>model_profile: str | None\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.flows.HighlightsGenerateCommand.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController <p>High-level intelligence operations using Prefect flows.</p> Functions <code></code> news_recap.brain.flows.IntelligenceCliController.add_feedback <pre><code>add_feedback(command: FeedbackAddCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.ask_qa <pre><code>ask_qa(command: QaAskCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.build_stories <pre><code>build_stories(command: StoryBuildCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.define_story <pre><code>define_story(command: StoryDefineCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.generate_highlights <pre><code>generate_highlights(command: HighlightsGenerateCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.generate_story_details <pre><code>generate_story_details(command: StoryDetailsGenerateCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.list_monitors <pre><code>list_monitors(command: MonitorListCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.list_outputs <pre><code>list_outputs(*, db_path: Path | None, kind: str | None = None, business_date: date | None = None, limit: int = 20) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.list_stories <pre><code>list_stories(command: StoryListCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.mark_read_state <pre><code>mark_read_state(command: ReadStateMarkCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.run_monitors <pre><code>run_monitors(command: MonitorRunCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.stats <pre><code>stats(command: IntelligenceStatsCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceCliController.upsert_monitor <pre><code>upsert_monitor(command: MonitorUpsertCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceStatsCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.IntelligenceStatsCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.IntelligenceStatsCommand.hours <code>instance-attribute</code> <pre><code>hours: int\n</code></pre> <code></code> news_recap.brain.flows.MonitorListCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.MonitorListCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorListCommand.include_disabled <code>instance-attribute</code> <pre><code>include_disabled: bool\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.MonitorRunCommand.agent <code>instance-attribute</code> <pre><code>agent: str | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.business_date <code>instance-attribute</code> <pre><code>business_date: date | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.max_attempts <code>instance-attribute</code> <pre><code>max_attempts: int\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.model <code>instance-attribute</code> <pre><code>model: str | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.model_profile <code>instance-attribute</code> <pre><code>model_profile: str | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.flows.MonitorRunCommand.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.MonitorUpsertCommand.cadence <code>instance-attribute</code> <pre><code>cadence: str\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand.enabled <code>instance-attribute</code> <pre><code>enabled: bool\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand.monitor_id <code>instance-attribute</code> <pre><code>monitor_id: str | None\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.flows.MonitorUpsertCommand.prompt <code>instance-attribute</code> <pre><code>prompt: str\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.QaAskCommand.agent <code>instance-attribute</code> <pre><code>agent: str | None\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.lookback_days <code>instance-attribute</code> <pre><code>lookback_days: int | None\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.max_attempts <code>instance-attribute</code> <pre><code>max_attempts: int\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.model <code>instance-attribute</code> <pre><code>model: str | None\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.model_profile <code>instance-attribute</code> <pre><code>model_profile: str | None\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.prompt <code>instance-attribute</code> <pre><code>prompt: str\n</code></pre> <code></code> news_recap.brain.flows.QaAskCommand.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.flows.ReadStateMarkCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.ReadStateMarkCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.ReadStateMarkCommand.event_type <code>instance-attribute</code> <pre><code>event_type: str\n</code></pre> <code></code> news_recap.brain.flows.ReadStateMarkCommand.output_block_id <code>instance-attribute</code> <pre><code>output_block_id: int | None\n</code></pre> <code></code> news_recap.brain.flows.ReadStateMarkCommand.output_id <code>instance-attribute</code> <pre><code>output_id: str\n</code></pre> <code></code> news_recap.brain.flows.StoryBuildCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.StoryBuildCommand.business_date <code>instance-attribute</code> <pre><code>business_date: date | None\n</code></pre> <code></code> news_recap.brain.flows.StoryBuildCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.StoryDefineCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.description <code>instance-attribute</code> <pre><code>description: str\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.enabled <code>instance-attribute</code> <pre><code>enabled: bool\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDefineCommand.target_language <code>instance-attribute</code> <pre><code>target_language: str\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.agent <code>instance-attribute</code> <pre><code>agent: str | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.business_date <code>instance-attribute</code> <pre><code>business_date: date | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.max_attempts <code>instance-attribute</code> <pre><code>max_attempts: int\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.model <code>instance-attribute</code> <pre><code>model: str | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.model_profile <code>instance-attribute</code> <pre><code>model_profile: str | None\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.story_id <code>instance-attribute</code> <pre><code>story_id: str\n</code></pre> <code></code> news_recap.brain.flows.StoryDetailsGenerateCommand.timeout_seconds <code>instance-attribute</code> <pre><code>timeout_seconds: int\n</code></pre> <code></code> news_recap.brain.flows.StoryListCommand <code>dataclass</code> Attributes <code></code> news_recap.brain.flows.StoryListCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.brain.flows.StoryListCommand.include_disabled <code>instance-attribute</code> <pre><code>include_disabled: bool\n</code></pre> Functions"},{"location":"reference/#news_recap.brain.models","title":"news_recap.brain.models","text":"<p>Domain models for intelligence layer: stories, monitors, outputs.</p> Classes news_recap.brain.models.DailyStorySnapshotView <code>dataclass</code> <p>Stored daily story snapshot.</p> Attributes <code></code> news_recap.brain.models.DailyStorySnapshotView.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.continuity_key <code>instance-attribute</code> <pre><code>continuity_key: str | None\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.story_key <code>instance-attribute</code> <pre><code>story_key: str\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.summary <code>instance-attribute</code> <pre><code>summary: dict[str, Any]\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotView.updated_at <code>instance-attribute</code> <pre><code>updated_at: datetime\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite <code>dataclass</code> <p>Per-day continuity snapshot for one story key.</p> Attributes <code></code> news_recap.brain.models.DailyStorySnapshotWrite.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite.continuity_key <code>instance-attribute</code> <pre><code>continuity_key: str | None\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite.story_key <code>instance-attribute</code> <pre><code>story_key: str\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite.summary <code>instance-attribute</code> <pre><code>summary: dict[str, Any]\n</code></pre> <code></code> news_recap.brain.models.DailyStorySnapshotWrite.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView <code>dataclass</code> <p>Stored monitor definition.</p> Attributes <code></code> news_recap.brain.models.MonitorQuestionView.cadence <code>instance-attribute</code> <pre><code>cadence: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.created_at <code>instance-attribute</code> <pre><code>created_at: datetime\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.enabled <code>instance-attribute</code> <pre><code>enabled: bool\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.monitor_id <code>instance-attribute</code> <pre><code>monitor_id: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.prompt <code>instance-attribute</code> <pre><code>prompt: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.updated_at <code>instance-attribute</code> <pre><code>updated_at: datetime\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionView.user_id <code>instance-attribute</code> <pre><code>user_id: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionWrite <code>dataclass</code> <p>Payload for monitor create/update.</p> Attributes <code></code> news_recap.brain.models.MonitorQuestionWrite.cadence <code>class-attribute</code> <code>instance-attribute</code> <pre><code>cadence: str = 'daily'\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionWrite.enabled <code>class-attribute</code> <code>instance-attribute</code> <pre><code>enabled: bool = True\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionWrite.monitor_id <code>instance-attribute</code> <pre><code>monitor_id: str | None\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionWrite.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.models.MonitorQuestionWrite.prompt <code>instance-attribute</code> <pre><code>prompt: str\n</code></pre> <code></code> news_recap.brain.models.OutputFeedbackWrite <code>dataclass</code> <p>Feedback event attached to output or output block.</p> Attributes <code></code> news_recap.brain.models.OutputFeedbackWrite.details <code>class-attribute</code> <code>instance-attribute</code> <pre><code>details: dict[str, Any] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.brain.models.OutputFeedbackWrite.feedback_type <code>instance-attribute</code> <pre><code>feedback_type: str\n</code></pre> <code></code> news_recap.brain.models.OutputFeedbackWrite.output_block_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_block_id: int | None = None\n</code></pre> <code></code> news_recap.brain.models.OutputFeedbackWrite.output_id <code>instance-attribute</code> <pre><code>output_id: str\n</code></pre> <code></code> news_recap.brain.models.OutputFeedbackWrite.value <code>class-attribute</code> <code>instance-attribute</code> <pre><code>value: str | None = None\n</code></pre> <code></code> news_recap.brain.models.ReadStateEventWrite <code>dataclass</code> <p>Read/open interaction event against stable output identity.</p> Attributes <code></code> news_recap.brain.models.ReadStateEventWrite.details <code>class-attribute</code> <code>instance-attribute</code> <pre><code>details: dict[str, Any] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.brain.models.ReadStateEventWrite.event_type <code>instance-attribute</code> <pre><code>event_type: str\n</code></pre> <code></code> news_recap.brain.models.ReadStateEventWrite.output_block_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_block_id: int | None = None\n</code></pre> <code></code> news_recap.brain.models.ReadStateEventWrite.output_id <code>instance-attribute</code> <pre><code>output_id: str\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry <code>dataclass</code> <p>User-scoped source entry resolved from shared articles via user link.</p> Attributes <code></code> news_recap.brain.models.SourceCorpusEntry.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.clean_text <code>class-attribute</code> <code>instance-attribute</code> <pre><code>clean_text: str = ''\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.published_at <code>instance-attribute</code> <pre><code>published_at: datetime\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.source <code>instance-attribute</code> <pre><code>source: str\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.source_id <code>instance-attribute</code> <pre><code>source_id: str\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.brain.models.SourceCorpusEntry.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentView <code>dataclass</code> <p>Stored article assignment for one business date.</p> Attributes <code></code> news_recap.brain.models.StoryAssignmentView.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentView.assignment_type <code>instance-attribute</code> <pre><code>assignment_type: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentView.score <code>instance-attribute</code> <pre><code>score: float\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentView.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentView.story_key <code>instance-attribute</code> <pre><code>story_key: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite <code>dataclass</code> <p>One user-scoped article to story assignment.</p> Attributes <code></code> news_recap.brain.models.StoryAssignmentWrite.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite.assignment_type <code>instance-attribute</code> <pre><code>assignment_type: str\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite.score <code>class-attribute</code> <code>instance-attribute</code> <pre><code>score: float = 0.0\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.StoryAssignmentWrite.story_key <code>instance-attribute</code> <pre><code>story_key: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView <code>dataclass</code> <p>Stored pinned story definition.</p> Attributes <code></code> news_recap.brain.models.StoryDefinitionView.created_at <code>instance-attribute</code> <pre><code>created_at: datetime\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.description <code>instance-attribute</code> <pre><code>description: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.enabled <code>instance-attribute</code> <pre><code>enabled: bool\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.priority <code>instance-attribute</code> <pre><code>priority: int\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.story_id <code>instance-attribute</code> <pre><code>story_id: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.target_language <code>instance-attribute</code> <pre><code>target_language: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.updated_at <code>instance-attribute</code> <pre><code>updated_at: datetime\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionView.user_id <code>instance-attribute</code> <pre><code>user_id: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite <code>dataclass</code> <p>Payload for creating/updating a pinned user story definition.</p> Attributes <code></code> news_recap.brain.models.StoryDefinitionWrite.description <code>instance-attribute</code> <pre><code>description: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite.enabled <code>class-attribute</code> <code>instance-attribute</code> <pre><code>enabled: bool = True\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite.priority <code>class-attribute</code> <code>instance-attribute</code> <pre><code>priority: int = 100\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.StoryDefinitionWrite.target_language <code>class-attribute</code> <code>instance-attribute</code> <pre><code>target_language: str = 'en'\n</code></pre> <code></code> news_recap.brain.models.UserOutputBlockWrite <code>dataclass</code> <p>One output block with strict source mapping.</p> Attributes <code></code> news_recap.brain.models.UserOutputBlockWrite.block_order <code>instance-attribute</code> <pre><code>block_order: int\n</code></pre> <code></code> news_recap.brain.models.UserOutputBlockWrite.source_ids <code>instance-attribute</code> <pre><code>source_ids: tuple[str, ...]\n</code></pre> <code></code> news_recap.brain.models.UserOutputBlockWrite.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert <code>dataclass</code> <p>Upsert payload for stable business output object.</p> Attributes <code></code> news_recap.brain.models.UserOutputUpsert.blocks <code>instance-attribute</code> <pre><code>blocks: list[UserOutputBlockWrite]\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.kind <code>instance-attribute</code> <pre><code>kind: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.monitor_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>monitor_id: str | None = None\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.payload <code>instance-attribute</code> <pre><code>payload: dict[str, Any]\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.request_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>request_id: str | None = None\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.status <code>instance-attribute</code> <pre><code>status: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.story_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_id: str | None = None\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.task_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>task_id: str | None = None\n</code></pre> <code></code> news_recap.brain.models.UserOutputUpsert.title <code>class-attribute</code> <code>instance-attribute</code> <pre><code>title: str | None = None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView <code>dataclass</code> <p>Stored business output record.</p> Attributes <code></code> news_recap.brain.models.UserOutputView.blocks <code>class-attribute</code> <code>instance-attribute</code> <pre><code>blocks: list[UserOutputBlockWrite] = field(default_factory=list)\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.created_at <code>instance-attribute</code> <pre><code>created_at: datetime\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.kind <code>instance-attribute</code> <pre><code>kind: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.monitor_id <code>instance-attribute</code> <pre><code>monitor_id: str | None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.output_id <code>instance-attribute</code> <pre><code>output_id: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.payload <code>instance-attribute</code> <pre><code>payload: dict[str, Any]\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.request_id <code>instance-attribute</code> <pre><code>request_id: str | None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.status <code>instance-attribute</code> <pre><code>status: str\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.story_id <code>instance-attribute</code> <pre><code>story_id: str | None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.task_id <code>instance-attribute</code> <pre><code>task_id: str | None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.title <code>instance-attribute</code> <pre><code>title: str | None\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.updated_at <code>instance-attribute</code> <pre><code>updated_at: datetime\n</code></pre> <code></code> news_recap.brain.models.UserOutputView.user_id <code>instance-attribute</code> <pre><code>user_id: str\n</code></pre>"},{"location":"reference/#news_recap.brain.pricing","title":"news_recap.brain.pricing","text":"<p>Token cost estimation helpers for LLM task attempts.</p> Attributes news_recap.brain.pricing.PRICING_SPEC_PARTS <code>module-attribute</code> <pre><code>PRICING_SPEC_PARTS = 4\n</code></pre> Classes <code></code> news_recap.brain.pricing.ModelPricing <code>dataclass</code> <p>Per-model input/output pricing in USD per 1M tokens.</p> Attributes <code></code> news_recap.brain.pricing.ModelPricing.input_per_1m <code>instance-attribute</code> <pre><code>input_per_1m: float\n</code></pre> <code></code> news_recap.brain.pricing.ModelPricing.output_per_1m <code>instance-attribute</code> <pre><code>output_per_1m: float\n</code></pre> Functions <code></code> news_recap.brain.pricing.estimate_cost_usd <pre><code>estimate_cost_usd(*, agent: str, model: str, prompt_tokens: int | None, completion_tokens: int | None, total_tokens: int | None) -&gt; float | None\n</code></pre> <p>Estimate task cost in USD from token usage and configured pricing.</p>"},{"location":"reference/#news_recap.brain.routing","title":"news_recap.brain.routing","text":"<p>Routing resolution helpers for per-task LLM execution.</p> Attributes news_recap.brain.routing.ROUTING_SCHEMA_VERSION <code>module-attribute</code> <pre><code>ROUTING_SCHEMA_VERSION = 1\n</code></pre> <code></code> news_recap.brain.routing.SUPPORTED_AGENTS <code>module-attribute</code> <pre><code>SUPPORTED_AGENTS = ('claude', 'codex', 'gemini')\n</code></pre> <code></code> news_recap.brain.routing.SUPPORTED_PROFILES <code>module-attribute</code> <pre><code>SUPPORTED_PROFILES = ('fast', 'quality')\n</code></pre> Classes <code></code> news_recap.brain.routing.FrozenRouting <code>dataclass</code> <p>Resolved immutable routing payload stored in task metadata.</p> Attributes <code></code> news_recap.brain.routing.FrozenRouting.agent <code>instance-attribute</code> <pre><code>agent: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.command_template <code>instance-attribute</code> <pre><code>command_template: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.model <code>instance-attribute</code> <pre><code>model: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.profile <code>instance-attribute</code> <pre><code>profile: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.resolved_at <code>instance-attribute</code> <pre><code>resolved_at: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.resolved_by <code>instance-attribute</code> <pre><code>resolved_by: str\n</code></pre> <code></code> news_recap.brain.routing.FrozenRouting.schema_version <code>instance-attribute</code> <pre><code>schema_version: int\n</code></pre> Functions <code></code> news_recap.brain.routing.FrozenRouting.to_metadata <pre><code>to_metadata() -&gt; dict[str, object]\n</code></pre> <p>Serialize frozen routing for task_input metadata.</p> <code></code> news_recap.brain.routing.RoutingDefaults <code>dataclass</code> <p>Settings snapshot used for enqueue-time routing and legacy fallback.</p> Attributes <code></code> news_recap.brain.routing.RoutingDefaults.command_templates <code>instance-attribute</code> <pre><code>command_templates: dict[str, str]\n</code></pre> <code></code> news_recap.brain.routing.RoutingDefaults.default_agent <code>instance-attribute</code> <pre><code>default_agent: str\n</code></pre> <code></code> news_recap.brain.routing.RoutingDefaults.models <code>instance-attribute</code> <pre><code>models: dict[str, dict[str, str]]\n</code></pre> <code></code> news_recap.brain.routing.RoutingDefaults.task_type_profile_map <code>instance-attribute</code> <pre><code>task_type_profile_map: dict[str, str]\n</code></pre> Functions <code></code> news_recap.brain.routing.RoutingDefaults.from_settings <code>classmethod</code> <pre><code>from_settings(settings: OrchestratorSettings) -&gt; RoutingDefaults\n</code></pre> <p>Build validated defaults from orchestrator settings.</p> Functions <code></code> news_recap.brain.routing.resolve_routing_for_enqueue <pre><code>resolve_routing_for_enqueue(*, defaults: RoutingDefaults, task_type: str, agent_override: str | None, profile_override: str | None, model_override: str | None) -&gt; FrozenRouting\n</code></pre> <p>Resolve and freeze routing at enqueue time.</p> <code></code> news_recap.brain.routing.resolve_routing_for_execution <pre><code>resolve_routing_for_execution(*, task_input: TaskInputContract, task_type: str, defaults: RoutingDefaults) -&gt; tuple[FrozenRouting, str | None]\n</code></pre> <p>Return frozen routing from metadata or deterministic fallback.</p>"},{"location":"reference/#news_recap.brain.sanitization","title":"news_recap.brain.sanitization","text":"<p>Sanitization helpers for attempt diagnostics persisted in DB.</p> Functions news_recap.brain.sanitization.sanitize_preview <pre><code>sanitize_preview(text: str, *, max_chars: int = _MAX_PREVIEW_CHARS) -&gt; str\n</code></pre> <p>Redact obvious secrets/PII and clamp payload size.</p>"},{"location":"reference/#news_recap.brain.usage","title":"news_recap.brain.usage","text":"<p>Usage extraction helpers for CLI agent output streams.</p> Attributes news_recap.brain.usage.USAGE_PARSER_VERSION <code>module-attribute</code> <pre><code>USAGE_PARSER_VERSION = 'v1'\n</code></pre> Classes <code></code> news_recap.brain.usage.UsageExtraction <code>dataclass</code> <p>Best-effort token usage extraction result.</p> Attributes <code></code> news_recap.brain.usage.UsageExtraction.completion_tokens <code>instance-attribute</code> <pre><code>completion_tokens: int | None\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.parser_version <code>instance-attribute</code> <pre><code>parser_version: str\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.prompt_tokens <code>instance-attribute</code> <pre><code>prompt_tokens: int | None\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.reason <code>class-attribute</code> <code>instance-attribute</code> <pre><code>reason: str | None = None\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.total_tokens <code>instance-attribute</code> <pre><code>total_tokens: int | None\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.usage_source <code>instance-attribute</code> <pre><code>usage_source: str\n</code></pre> <code></code> news_recap.brain.usage.UsageExtraction.usage_status <code>instance-attribute</code> <pre><code>usage_status: str\n</code></pre> Functions <code></code> news_recap.brain.usage.extract_usage <pre><code>extract_usage(*, agent: str, stdout: str, stderr: str) -&gt; UsageExtraction\n</code></pre> <p>Extract token usage from structured or textual backend output.</p>"},{"location":"reference/#news_recap.brain.workdir","title":"news_recap.brain.workdir","text":"<p>Workdir materialization helpers for file-based task execution.</p> Classes news_recap.brain.workdir.MaterializedTask <code>dataclass</code> <p>Materialized file-based task contract paths.</p> Attributes <code></code> news_recap.brain.workdir.MaterializedTask.manifest <code>instance-attribute</code> <pre><code>manifest: TaskManifest\n</code></pre> <code></code> news_recap.brain.workdir.MaterializedTask.manifest_path <code>instance-attribute</code> <pre><code>manifest_path: Path\n</code></pre> <code></code> news_recap.brain.workdir.TaskWorkdirManager <p>Creates deterministic per-task directory layout.</p> Attributes <code></code> news_recap.brain.workdir.TaskWorkdirManager.root_dir <code>instance-attribute</code> <pre><code>root_dir = root_dir\n</code></pre> Functions <code></code> news_recap.brain.workdir.TaskWorkdirManager.materialize <pre><code>materialize(*, task_id: str, task_type: str, task_input: TaskInputContract, articles_index: list[ArticleIndexEntry], continuity_summary: dict[str, object] | None = None, retrieval_context: dict[str, object] | None = None, story_context: dict[str, object] | None = None, extra_input_files: dict[str, str | bytes] | None = None, output_schema_hint: str | None = None) -&gt; MaterializedTask\n</code></pre> Functions"},{"location":"reference/#news_recap.config","title":"news_recap.config","text":"<p>Runtime configuration for ingestion and dedup pipeline.</p>"},{"location":"reference/#news_recap.config-attributes","title":"Attributes","text":""},{"location":"reference/#news_recap.config.logger","title":"news_recap.config.logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger(__name__)\n</code></pre>"},{"location":"reference/#news_recap.config-classes","title":"Classes","text":""},{"location":"reference/#news_recap.config.DedupSettings","title":"news_recap.config.DedupSettings  <code>dataclass</code>","text":"<p>Semantic deduplication settings.</p> Attributes news_recap.config.DedupSettings.allow_model_fallback <code>class-attribute</code> <code>instance-attribute</code> <pre><code>allow_model_fallback: bool = False\n</code></pre> <code></code> news_recap.config.DedupSettings.embedding_ttl_days <code>class-attribute</code> <code>instance-attribute</code> <pre><code>embedding_ttl_days: int = 7\n</code></pre> <code></code> news_recap.config.DedupSettings.enabled <code>class-attribute</code> <code>instance-attribute</code> <pre><code>enabled: bool = False\n</code></pre> <code></code> news_recap.config.DedupSettings.lookback_days <code>class-attribute</code> <code>instance-attribute</code> <pre><code>lookback_days: int = 3\n</code></pre> <code></code> news_recap.config.DedupSettings.model_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>model_name: str = 'intfloat/multilingual-e5-small'\n</code></pre> <code></code> news_recap.config.DedupSettings.threshold <code>class-attribute</code> <code>instance-attribute</code> <pre><code>threshold: float = 0.95\n</code></pre>"},{"location":"reference/#news_recap.config.IngestionSettings","title":"news_recap.config.IngestionSettings  <code>dataclass</code>","text":"<p>Generic ingestion-stage settings.</p> Attributes news_recap.config.IngestionSettings.active_run_stale_after_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>active_run_stale_after_seconds: int = 1800\n</code></pre> <code></code> news_recap.config.IngestionSettings.article_retention_days <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_retention_days: int = 30\n</code></pre> <code></code> news_recap.config.IngestionSettings.backfill_max_gaps <code>class-attribute</code> <code>instance-attribute</code> <pre><code>backfill_max_gaps: int = 10\n</code></pre> <code></code> news_recap.config.IngestionSettings.clean_text_max_chars <code>class-attribute</code> <code>instance-attribute</code> <pre><code>clean_text_max_chars: int = 12000\n</code></pre> <code></code> news_recap.config.IngestionSettings.max_pages <code>class-attribute</code> <code>instance-attribute</code> <pre><code>max_pages: int = 0\n</code></pre> <code></code> news_recap.config.IngestionSettings.page_size <code>class-attribute</code> <code>instance-attribute</code> <pre><code>page_size: int = 50\n</code></pre>"},{"location":"reference/#news_recap.config.OrchestratorSettings","title":"news_recap.config.OrchestratorSettings  <code>dataclass</code>","text":"<p>CLI orchestrator settings.</p> Attributes news_recap.config.OrchestratorSettings.backend_capability_mode <code>class-attribute</code> <code>instance-attribute</code> <pre><code>backend_capability_mode: str = 'manifest_native'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.claude_command_template <code>class-attribute</code> <code>instance-attribute</code> <pre><code>claude_command_template: str = 'claude -p --model {model} --permission-mode dontAsk --allowed-tools \"Read,Write,Edit,WebFetch,Bash(curl:*),Bash(cat:*),Bash(shasum:*),Bash(pwd:*),Bash(ls:*)\" -- \"Read your task from {prompt_file} and execute it.\"'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.claude_model_fast <code>class-attribute</code> <code>instance-attribute</code> <pre><code>claude_model_fast: str = 'sonnet'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.claude_model_quality <code>class-attribute</code> <code>instance-attribute</code> <pre><code>claude_model_quality: str = 'opus'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.codex_command_template <code>class-attribute</code> <code>instance-attribute</code> <pre><code>codex_command_template: str = 'codex exec --sandbox workspace-write -c sandbox_workspace_write.network_access=true {model} \"Read your task from {prompt_file} and execute it.\"'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.codex_model_fast <code>class-attribute</code> <code>instance-attribute</code> <pre><code>codex_model_fast: str = '--model gpt-5.2 -c model_reasoning_effort=medium'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.codex_model_quality <code>class-attribute</code> <code>instance-attribute</code> <pre><code>codex_model_quality: str = '--model gpt-5.2 -c model_reasoning_effort=high'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.default_agent <code>class-attribute</code> <code>instance-attribute</code> <pre><code>default_agent: str = 'codex'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.gemini_command_template <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gemini_command_template: str = 'gemini --model {model} --approval-mode auto_edit --prompt \"Read your task from {prompt_file} and execute it.\"'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.gemini_model_fast <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gemini_model_fast: str = 'gemini-2.5-flash'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.gemini_model_quality <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gemini_model_quality: str = 'gemini-2.5-pro'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.poll_interval_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>poll_interval_seconds: float = 2.0\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.qa_lookback_days <code>class-attribute</code> <code>instance-attribute</code> <pre><code>qa_lookback_days: int = 3\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retrieval_char_budget <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retrieval_char_budget: int = 60000\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retrieval_max_articles <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retrieval_max_articles: int = 80\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retrieval_token_budget <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retrieval_token_budget: int = 12000\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retrieval_top_k <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retrieval_top_k: int = 40\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retry_base_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_base_seconds: int = 30\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.retry_max_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_max_seconds: int = 900\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.task_type_profile_map <code>class-attribute</code> <code>instance-attribute</code> <pre><code>task_type_profile_map: dict[str, str] = field(default_factory=lambda: {'highlights': 'fast', 'story': 'quality', 'qa': 'fast', 'recap_classify': 'fast', 'recap_enrich': 'fast', 'recap_group': 'fast', 'recap_enrich_full': 'fast', 'recap_synthesize': 'quality', 'recap_compose': 'quality'})\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.workdir_root <code>class-attribute</code> <code>instance-attribute</code> <pre><code>workdir_root: Path = Path('.news_recap_workdir')\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.worker_graceful_shutdown_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>worker_graceful_shutdown_seconds: int = 30\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.worker_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>worker_id: str = 'worker-default'\n</code></pre> <code></code> news_recap.config.OrchestratorSettings.worker_stale_attempt_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>worker_stale_attempt_seconds: int = 1800\n</code></pre>"},{"location":"reference/#news_recap.config.PrefectMode","title":"news_recap.config.PrefectMode","text":"<p>               Bases: <code>Enum</code></p> <p>Execution mode for the Prefect-based recap pipeline.</p> Attributes <code></code> news_recap.config.PrefectMode.AUTO <code>class-attribute</code> <code>instance-attribute</code> <pre><code>AUTO = 'auto'\n</code></pre> <code></code> news_recap.config.PrefectMode.EPHEMERAL <code>class-attribute</code> <code>instance-attribute</code> <pre><code>EPHEMERAL = 'ephemeral'\n</code></pre> <code></code> news_recap.config.PrefectMode.SERVER <code>class-attribute</code> <code>instance-attribute</code> <pre><code>SERVER = 'server'\n</code></pre>"},{"location":"reference/#news_recap.config.RssSettings","title":"news_recap.config.RssSettings  <code>dataclass</code>","text":"<p>RSS source settings.</p> Attributes news_recap.config.RssSettings.default_items_per_feed <code>class-attribute</code> <code>instance-attribute</code> <pre><code>default_items_per_feed: int = 10000\n</code></pre> <code></code> news_recap.config.RssSettings.feed_urls <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feed_urls: tuple[str, ...] = ()\n</code></pre> <code></code> news_recap.config.RssSettings.max_retries <code>class-attribute</code> <code>instance-attribute</code> <pre><code>max_retries: int = 3\n</code></pre> <code></code> news_recap.config.RssSettings.per_feed_items <code>class-attribute</code> <code>instance-attribute</code> <pre><code>per_feed_items: dict[str, int] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.config.RssSettings.request_timeout_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>request_timeout_seconds: float = 30.0\n</code></pre> <code></code> news_recap.config.RssSettings.retry_backoff_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_backoff_seconds: float = 1.0\n</code></pre> <code></code> news_recap.config.RssSettings.snapshot_max_age_hours <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_max_age_hours: int = 24\n</code></pre>"},{"location":"reference/#news_recap.config.Settings","title":"news_recap.config.Settings  <code>dataclass</code>","text":"<p>Application settings grouped by domain concerns.</p> Attributes news_recap.config.Settings.db_path <code>class-attribute</code> <code>instance-attribute</code> <pre><code>db_path: Path = Path('.news_recap.db')\n</code></pre> <code></code> news_recap.config.Settings.dedup <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup: DedupSettings = field(default_factory=DedupSettings)\n</code></pre> <code></code> news_recap.config.Settings.ingestion <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ingestion: IngestionSettings = field(default_factory=IngestionSettings)\n</code></pre> <code></code> news_recap.config.Settings.orchestrator <code>class-attribute</code> <code>instance-attribute</code> <pre><code>orchestrator: OrchestratorSettings = field(default_factory=OrchestratorSettings)\n</code></pre> <code></code> news_recap.config.Settings.rss <code>class-attribute</code> <code>instance-attribute</code> <pre><code>rss: RssSettings = field(default_factory=RssSettings)\n</code></pre> <code></code> news_recap.config.Settings.sqlite_busy_timeout_ms <code>class-attribute</code> <code>instance-attribute</code> <pre><code>sqlite_busy_timeout_ms: int = 5000\n</code></pre> <code></code> news_recap.config.Settings.user_context <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_context: UserContextSettings = field(default_factory=UserContextSettings)\n</code></pre> Functions <code></code> news_recap.config.Settings.from_env <code>classmethod</code> <pre><code>from_env(db_path: Path | None = None) -&gt; Settings\n</code></pre> <p>Load settings from environment with sane defaults for local development.</p> <code></code> news_recap.config.Settings.validate <pre><code>validate() -&gt; None\n</code></pre> <p>Validate cross-domain runtime settings and fail fast on invalid config.</p> <code></code> news_recap.config.Settings.validate_for_rss <pre><code>validate_for_rss(override_feed_urls: tuple[str, ...] = ()) -&gt; None\n</code></pre> <p>Raise configuration error if RSS feed URLs are missing or invalid.</p>"},{"location":"reference/#news_recap.config.UserContextSettings","title":"news_recap.config.UserContextSettings  <code>dataclass</code>","text":"<p>User context settings.</p> Attributes news_recap.config.UserContextSettings.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = 'default_user'\n</code></pre> <code></code> news_recap.config.UserContextSettings.user_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_name: str = 'Default User'\n</code></pre>"},{"location":"reference/#news_recap.config-functions","title":"Functions","text":""},{"location":"reference/#news_recap.config.configure_prefect_runtime","title":"news_recap.config.configure_prefect_runtime","text":"<pre><code>configure_prefect_runtime(mode: PrefectMode) -&gt; PrefectMode\n</code></pre> <p>Configure Prefect for mode and return the effective mode.</p> <ul> <li><code>EPHEMERAL</code>: unset <code>PREFECT_API_URL</code>; run locally.</li> <li><code>SERVER</code>: require <code>PREFECT_API_URL</code>; fail fast if unreachable.</li> <li><code>AUTO</code>: probe <code>PREFECT_API_URL</code> (\u2264500 ms); fall back to ephemeral.</li> </ul>"},{"location":"reference/#news_recap.config.resolve_prefect_mode","title":"news_recap.config.resolve_prefect_mode","text":"<pre><code>resolve_prefect_mode() -&gt; PrefectMode\n</code></pre> <p>Resolve Prefect execution mode from <code>NEWS_RECAP_PREFECT_MODE</code>.</p>"},{"location":"reference/#news_recap.http","title":"news_recap.http","text":"<p>Shared HTTP fetching and content extraction utilities.</p>"},{"location":"reference/#news_recap.http-modules","title":"Modules","text":""},{"location":"reference/#news_recap.http.fetcher","title":"news_recap.http.fetcher","text":"<p>Async-capable HTTP client with retries and timeout.</p> Attributes news_recap.http.fetcher.DEFAULT_MAX_RETRIES <code>module-attribute</code> <pre><code>DEFAULT_MAX_RETRIES = 3\n</code></pre> <code></code> news_recap.http.fetcher.DEFAULT_TIMEOUT_SECONDS <code>module-attribute</code> <pre><code>DEFAULT_TIMEOUT_SECONDS = 30.0\n</code></pre> <code></code> news_recap.http.fetcher.DEFAULT_USER_AGENT <code>module-attribute</code> <pre><code>DEFAULT_USER_AGENT = 'Mozilla/5.0 (compatible; NewsRecapBot/1.0; +https://github.com/andgineer/news-recap)'\n</code></pre> <code></code> news_recap.http.fetcher.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.http.fetcher.FetchResult <code>dataclass</code> <p>Result of an HTTP fetch operation.</p> Attributes <code></code> news_recap.http.fetcher.FetchResult.content <code>instance-attribute</code> <pre><code>content: str\n</code></pre> <code></code> news_recap.http.fetcher.FetchResult.content_type <code>instance-attribute</code> <pre><code>content_type: str\n</code></pre> <code></code> news_recap.http.fetcher.FetchResult.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.http.fetcher.FetchResult.is_success <code>instance-attribute</code> <pre><code>is_success: bool\n</code></pre> <code></code> news_recap.http.fetcher.FetchResult.status_code <code>instance-attribute</code> <pre><code>status_code: int\n</code></pre> <code></code> news_recap.http.fetcher.FetchResult.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.http.fetcher.HttpFetcher <p>HTTP client wrapper with retry, timeout, and user-agent configuration.</p> Functions <code></code> news_recap.http.fetcher.HttpFetcher.close <pre><code>close() -&gt; None\n</code></pre> <code></code> news_recap.http.fetcher.HttpFetcher.fetch <pre><code>fetch(url: str) -&gt; FetchResult\n</code></pre> <p>Fetch URL content, returning structured result.</p>"},{"location":"reference/#news_recap.http.html_extractor","title":"news_recap.http.html_extractor","text":"<p>HTML to clean text extraction using trafilatura.</p> Attributes news_recap.http.html_extractor.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.http.html_extractor.ExtractionResult <code>dataclass</code> <p>Result of HTML text extraction.</p> Attributes <code></code> news_recap.http.html_extractor.ExtractionResult.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.http.html_extractor.ExtractionResult.is_success <code>instance-attribute</code> <pre><code>is_success: bool\n</code></pre> <code></code> news_recap.http.html_extractor.ExtractionResult.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> Functions <code></code> news_recap.http.html_extractor.extract_text <pre><code>extract_text(html: str, *, url: str | None = None, include_tables: bool = True, include_links: bool = False, max_chars: int = 0) -&gt; ExtractionResult\n</code></pre> <p>Extract main content text from HTML using trafilatura.</p> <p>Falls back to a simpler extraction if main extraction fails.</p>"},{"location":"reference/#news_recap.http.youtube_extractor","title":"news_recap.http.youtube_extractor","text":"<p>YouTube video subtitle/transcript extraction.</p> Attributes news_recap.http.youtube_extractor.PREFERRED_LANGUAGES <code>module-attribute</code> <pre><code>PREFERRED_LANGUAGES = ('ru', 'en', 'sr', 'uk', 'de', 'fr')\n</code></pre> <code></code> news_recap.http.youtube_extractor.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.http.youtube_extractor.TranscriptResult <code>dataclass</code> <p>Result of YouTube transcript extraction.</p> Attributes <code></code> news_recap.http.youtube_extractor.TranscriptResult.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.http.youtube_extractor.TranscriptResult.is_success <code>instance-attribute</code> <pre><code>is_success: bool\n</code></pre> <code></code> news_recap.http.youtube_extractor.TranscriptResult.language <code>instance-attribute</code> <pre><code>language: str\n</code></pre> <code></code> news_recap.http.youtube_extractor.TranscriptResult.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> Functions <code></code> news_recap.http.youtube_extractor.extract_video_id <pre><code>extract_video_id(url: str) -&gt; str | None\n</code></pre> <p>Extract YouTube video ID from URL, or None if not a YouTube URL.</p> <code></code> news_recap.http.youtube_extractor.fetch_transcript <pre><code>fetch_transcript(url: str, *, languages: tuple[str, ...] = PREFERRED_LANGUAGES, max_chars: int = 0) -&gt; TranscriptResult\n</code></pre> <p>Fetch transcript/subtitles for a YouTube video URL.</p> <p>Uses youtube-transcript-api v1.x: instance-based API with dataclass snippets. Tries preferred languages first via the high-level <code>fetch()</code> method, then falls back to the first available transcript.</p> <code></code> news_recap.http.youtube_extractor.is_youtube_url <pre><code>is_youtube_url(url: str) -&gt; bool\n</code></pre> <p>Check if URL points to a YouTube video.</p>"},{"location":"reference/#news_recap.ingestion","title":"news_recap.ingestion","text":"<p>Ingestion pipeline package.</p>"},{"location":"reference/#news_recap.ingestion-modules","title":"Modules","text":""},{"location":"reference/#news_recap.ingestion.cleaning","title":"news_recap.ingestion.cleaning","text":"<p>HTML to text cleaning and normalization utilities.</p> Classes news_recap.ingestion.cleaning.CleanedText <code>dataclass</code> <p>Output of HTML to text cleaning.</p> Attributes <code></code> news_recap.ingestion.cleaning.CleanedText.is_full_content <code>instance-attribute</code> <pre><code>is_full_content: bool\n</code></pre> <code></code> news_recap.ingestion.cleaning.CleanedText.is_truncated <code>instance-attribute</code> <pre><code>is_truncated: bool\n</code></pre> <code></code> news_recap.ingestion.cleaning.CleanedText.needs_enrichment <code>instance-attribute</code> <pre><code>needs_enrichment: bool\n</code></pre> <code></code> news_recap.ingestion.cleaning.CleanedText.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> Functions <code></code> news_recap.ingestion.cleaning.canonicalize_url <pre><code>canonicalize_url(url: str) -&gt; str\n</code></pre> <p>Normalize URL for idempotent hashing and uniqueness checks.</p> <code></code> news_recap.ingestion.cleaning.clean_article_text <pre><code>clean_article_text(*, content_html: str | None, summary_html: str | None, max_chars: int, full_content_min_chars: int = 700) -&gt; CleanedText\n</code></pre> <p>Clean HTML payload and infer whether full content is available.</p> <code></code> news_recap.ingestion.cleaning.extract_domain <pre><code>extract_domain(url: str) -&gt; str\n</code></pre> <p>Get normalized domain from URL.</p> <code></code> news_recap.ingestion.cleaning.html_to_text <pre><code>html_to_text(raw_html: str) -&gt; str\n</code></pre> <p>Convert HTML markup into normalized plain text.</p> <code></code> news_recap.ingestion.cleaning.url_hash <pre><code>url_hash(url: str) -&gt; str\n</code></pre> <p>Stable hash of canonical URL.</p>"},{"location":"reference/#news_recap.ingestion.controllers","title":"news_recap.ingestion.controllers","text":"<p>Controllers for ingestion CLI commands.</p> Classes news_recap.ingestion.controllers.DailyIngestionCommand <code>dataclass</code> <p>CLI inputs for daily ingestion command.</p> Attributes <code></code> news_recap.ingestion.controllers.DailyIngestionCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.DailyIngestionCommand.feed_urls <code>instance-attribute</code> <pre><code>feed_urls: tuple[str, ...]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController <p>Coordinates ingestion command execution.</p> Functions <code></code> news_recap.ingestion.controllers.IngestionCliController.clusters <pre><code>clusters(command: IngestionClustersCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController.duplicates <pre><code>duplicates(command: IngestionDuplicatesCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController.gc <pre><code>gc(command: IngestionGcCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController.prune <pre><code>prune(command: IngestionPruneCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController.run_daily <pre><code>run_daily(command: DailyIngestionCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionCliController.stats <pre><code>stats(command: IngestionStatsCommand) -&gt; list[str]\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand <code>dataclass</code> <p>CLI inputs for cluster inspection command.</p> Attributes <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.hours <code>instance-attribute</code> <pre><code>hours: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.limit <code>instance-attribute</code> <pre><code>limit: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.members_per_cluster <code>instance-attribute</code> <pre><code>members_per_cluster: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.min_size <code>instance-attribute</code> <pre><code>min_size: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.run_id <code>instance-attribute</code> <pre><code>run_id: str | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.show_members <code>instance-attribute</code> <pre><code>show_members: bool\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionClustersCommand.source <code>instance-attribute</code> <pre><code>source: str | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand <code>dataclass</code> <p>CLI inputs for duplicate sample command.</p> Attributes <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.hours <code>instance-attribute</code> <pre><code>hours: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.limit_clusters <code>instance-attribute</code> <pre><code>limit_clusters: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.members_per_cluster <code>instance-attribute</code> <pre><code>members_per_cluster: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.run_id <code>instance-attribute</code> <pre><code>run_id: str | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionDuplicatesCommand.source <code>instance-attribute</code> <pre><code>source: str | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionGcCommand <code>dataclass</code> <p>CLI inputs for global GC command.</p> Attributes <code></code> news_recap.ingestion.controllers.IngestionGcCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionGcCommand.dry_run <code>instance-attribute</code> <pre><code>dry_run: bool\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionPruneCommand <code>dataclass</code> <p>CLI inputs for retention prune command.</p> Attributes <code></code> news_recap.ingestion.controllers.IngestionPruneCommand.days <code>instance-attribute</code> <pre><code>days: int | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionPruneCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionPruneCommand.dry_run <code>instance-attribute</code> <pre><code>dry_run: bool\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionStatsCommand <code>dataclass</code> <p>CLI inputs for stats command.</p> Attributes <code></code> news_recap.ingestion.controllers.IngestionStatsCommand.db_path <code>instance-attribute</code> <pre><code>db_path: Path | None\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionStatsCommand.hours <code>instance-attribute</code> <pre><code>hours: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionStatsCommand.recent_runs <code>instance-attribute</code> <pre><code>recent_runs: int\n</code></pre> <code></code> news_recap.ingestion.controllers.IngestionStatsCommand.source <code>instance-attribute</code> <pre><code>source: str | None\n</code></pre> Functions"},{"location":"reference/#news_recap.ingestion.dedup","title":"news_recap.ingestion.dedup","text":"<p>Semantic deduplication modules.</p> Modules news_recap.ingestion.dedup.calibration <p>Golden-set utilities for dedup threshold calibration.</p> Attributes news_recap.ingestion.dedup.calibration.MANDATORY_MODELS <code>module-attribute</code> <pre><code>MANDATORY_MODELS = ('intfloat/multilingual-e5-small', 'intfloat/multilingual-e5-base')\n</code></pre> Classes <code></code> news_recap.ingestion.dedup.calibration.GoldenPair <code>dataclass</code> <p>Labeled pair for dedup threshold calibration.</p> Attributes <code></code> news_recap.ingestion.dedup.calibration.GoldenPair.label <code>instance-attribute</code> <pre><code>label: int\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.GoldenPair.left_text <code>instance-attribute</code> <pre><code>left_text: str\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.GoldenPair.right_text <code>instance-attribute</code> <pre><code>right_text: str\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ModelBenchmark <code>dataclass</code> <p>Benchmark result for one model candidate.</p> Attributes <code></code> news_recap.ingestion.dedup.calibration.ModelBenchmark.mean_similarity_duplicate <code>instance-attribute</code> <pre><code>mean_similarity_duplicate: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ModelBenchmark.mean_similarity_non_duplicate <code>instance-attribute</code> <pre><code>mean_similarity_non_duplicate: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ModelBenchmark.model_name <code>instance-attribute</code> <pre><code>model_name: str\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ModelBenchmark.throughput_pairs_per_second <code>instance-attribute</code> <pre><code>throughput_pairs_per_second: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ThresholdMetrics <code>dataclass</code> <p>Precision/recall summary at a threshold.</p> Attributes <code></code> news_recap.ingestion.dedup.calibration.ThresholdMetrics.f1 <code>instance-attribute</code> <pre><code>f1: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ThresholdMetrics.precision <code>instance-attribute</code> <pre><code>precision: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ThresholdMetrics.recall <code>instance-attribute</code> <pre><code>recall: float\n</code></pre> <code></code> news_recap.ingestion.dedup.calibration.ThresholdMetrics.threshold <code>instance-attribute</code> <pre><code>threshold: float\n</code></pre> Functions <code></code> news_recap.ingestion.dedup.calibration.benchmark_models <pre><code>benchmark_models(pairs: list[GoldenPair], model_names: list[str]) -&gt; list[ModelBenchmark]\n</code></pre> <p>Benchmark embedding models for quality separation and CPU throughput.</p> <code></code> news_recap.ingestion.dedup.calibration.evaluate_threshold <pre><code>evaluate_threshold(pairs: list[GoldenPair], similarities: list[float], threshold: float) -&gt; ThresholdMetrics\n</code></pre> <p>Compute precision/recall/F1 for duplicate detection.</p> <code></code> news_recap.ingestion.dedup.calibration.load_golden_pairs <pre><code>load_golden_pairs(path: Path) -&gt; list[GoldenPair]\n</code></pre> <p>Load golden set CSV with columns: left_text,right_text,label.</p> <code></code> news_recap.ingestion.dedup.calibration.pick_best_threshold <pre><code>pick_best_threshold(pairs: list[GoldenPair], similarities: list[float], candidates: list[float] | None = None) -&gt; ThresholdMetrics\n</code></pre> <p>Find threshold with best F1 among candidate values.</p> <code></code> news_recap.ingestion.dedup.cluster <p>Clustering logic for semantic deduplication.</p> Attributes Classes Functions <code></code> news_recap.ingestion.dedup.cluster.cluster_candidates <pre><code>cluster_candidates(candidates: list[DedupCandidate], embeddings: dict[str, Vector], threshold: float) -&gt; list[DedupCluster]\n</code></pre> <p>Cluster candidates by pairwise similarity threshold.</p> <code></code> news_recap.ingestion.dedup.cluster.count_duplicates <pre><code>count_duplicates(clusters: list[DedupCluster]) -&gt; int\n</code></pre> <p>Count duplicate (non-representative) items across all clusters.</p> <code></code> news_recap.ingestion.dedup.embedder <p>Embedding abstractions for semantic deduplication.</p> Attributes <code></code> news_recap.ingestion.dedup.embedder.Vector <code>module-attribute</code> <pre><code>Vector = list[float]\n</code></pre> Classes <code></code> news_recap.ingestion.dedup.embedder.Embedder <p>               Bases: <code>Protocol</code></p> <p>Embedding backend interface.</p> Attributes <code></code> news_recap.ingestion.dedup.embedder.Embedder.model_name <code>instance-attribute</code> <pre><code>model_name: str\n</code></pre> Functions <code></code> news_recap.ingestion.dedup.embedder.Embedder.embed <pre><code>embed(texts: list[str]) -&gt; list[Vector]\n</code></pre> <p>Encode texts into normalized vectors.</p> <code></code> news_recap.ingestion.dedup.embedder.HashingEmbedder <code>dataclass</code> <p>CPU-friendly fallback embedder based on hashed character n-grams.</p> Attributes <code></code> news_recap.ingestion.dedup.embedder.HashingEmbedder.dimensions <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dimensions: int = 384\n</code></pre> <code></code> news_recap.ingestion.dedup.embedder.HashingEmbedder.model_name <code>instance-attribute</code> <pre><code>model_name: str\n</code></pre> <code></code> news_recap.ingestion.dedup.embedder.HashingEmbedder.ngram_size <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ngram_size: int = 3\n</code></pre> Functions <code></code> news_recap.ingestion.dedup.embedder.HashingEmbedder.embed <pre><code>embed(texts: list[str]) -&gt; list[Vector]\n</code></pre> <code></code> news_recap.ingestion.dedup.embedder.SentenceTransformerEmbedder <code>dataclass</code> <p>Sentence-transformers backend with lazy import.</p> Attributes <code></code> news_recap.ingestion.dedup.embedder.SentenceTransformerEmbedder.model_name <code>instance-attribute</code> <pre><code>model_name: str\n</code></pre> Functions <code></code> news_recap.ingestion.dedup.embedder.SentenceTransformerEmbedder.embed <pre><code>embed(texts: list[str]) -&gt; list[Vector]\n</code></pre> Functions <code></code> news_recap.ingestion.dedup.embedder.build_embedder <pre><code>build_embedder(model_name: str, *, allow_fallback: bool = False) -&gt; Embedder\n</code></pre> <p>Build the configured embedder.</p> <p>For multilingual E5 models, fallback is explicit to avoid silent quality degradation.</p> <code></code> news_recap.ingestion.dedup.embedder.cosine_similarity <pre><code>cosine_similarity(left: Vector, right: Vector) -&gt; float\n</code></pre> <p>Compute cosine similarity for normalized vectors.</p>"},{"location":"reference/#news_recap.ingestion.language","title":"news_recap.ingestion.language","text":"<p>Lightweight language detection for RU/SR/EN.</p> Functions news_recap.ingestion.language.detect_language <pre><code>detect_language(text: str, title: str = '') -&gt; str\n</code></pre> <p>Detect language using script and marker heuristics.</p> <p>Returns one of: <code>ru</code>, <code>sr</code>, <code>en</code>, <code>unknown</code>.</p>"},{"location":"reference/#news_recap.ingestion.models","title":"news_recap.ingestion.models","text":"<p>Domain models for ingestion, storage, and dedup stages.</p> Classes news_recap.ingestion.models.ClusterListResult <code>dataclass</code> <p>Paginated view of clusters for one ingestion run.</p> Attributes <code></code> news_recap.ingestion.models.ClusterListResult.clusters <code>instance-attribute</code> <pre><code>clusters: list[ClusterPreview]\n</code></pre> <code></code> news_recap.ingestion.models.ClusterListResult.run_id <code>instance-attribute</code> <pre><code>run_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterListResult.total_articles <code>instance-attribute</code> <pre><code>total_articles: int\n</code></pre> <code></code> news_recap.ingestion.models.ClusterListResult.total_clusters <code>instance-attribute</code> <pre><code>total_clusters: int\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMember <code>dataclass</code> <p>Dedup cluster member metadata.</p> Attributes <code></code> news_recap.ingestion.models.ClusterMember.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMember.is_representative <code>instance-attribute</code> <pre><code>is_representative: bool\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMember.similarity_to_representative <code>instance-attribute</code> <pre><code>similarity_to_representative: float\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview <code>dataclass</code> <p>Readable article entry for cluster inspection.</p> Attributes <code></code> news_recap.ingestion.models.ClusterMemberPreview.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview.is_representative <code>instance-attribute</code> <pre><code>is_representative: bool\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview.similarity_to_representative <code>instance-attribute</code> <pre><code>similarity_to_representative: float\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview.source_domain <code>instance-attribute</code> <pre><code>source_domain: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterMemberPreview.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview <code>dataclass</code> <p>Cluster details for observability commands.</p> Attributes <code></code> news_recap.ingestion.models.ClusterPreview.cluster_id <code>instance-attribute</code> <pre><code>cluster_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.members <code>class-attribute</code> <code>instance-attribute</code> <pre><code>members: list[ClusterMemberPreview] = field(default_factory=list)\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.representative_article_id <code>instance-attribute</code> <pre><code>representative_article_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.representative_title <code>instance-attribute</code> <pre><code>representative_title: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.representative_url <code>instance-attribute</code> <pre><code>representative_url: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.run_id <code>instance-attribute</code> <pre><code>run_id: str\n</code></pre> <code></code> news_recap.ingestion.models.ClusterPreview.size <code>instance-attribute</code> <pre><code>size: int\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate <code>dataclass</code> <p>Article view used by deduplication stage.</p> Attributes <code></code> news_recap.ingestion.models.DedupCandidate.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.clean_text <code>instance-attribute</code> <pre><code>clean_text: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.clean_text_chars <code>instance-attribute</code> <pre><code>clean_text_chars: int\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.published_at <code>instance-attribute</code> <pre><code>published_at: datetime\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.source_domain <code>instance-attribute</code> <pre><code>source_domain: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCandidate.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCluster <code>dataclass</code> <p>Dedup cluster with representative and alternative sources.</p> Attributes <code></code> news_recap.ingestion.models.DedupCluster.alt_sources <code>instance-attribute</code> <pre><code>alt_sources: list[dict[str, str]]\n</code></pre> <code></code> news_recap.ingestion.models.DedupCluster.cluster_id <code>instance-attribute</code> <pre><code>cluster_id: str\n</code></pre> <code></code> news_recap.ingestion.models.DedupCluster.members <code>instance-attribute</code> <pre><code>members: list[ClusterMember]\n</code></pre> <code></code> news_recap.ingestion.models.DedupCluster.representative_article_id <code>instance-attribute</code> <pre><code>representative_article_id: str\n</code></pre> <code></code> news_recap.ingestion.models.GapStatus <p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Lifecycle states for ingestion gaps.</p> Attributes <code></code> news_recap.ingestion.models.GapStatus.EXPIRED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>EXPIRED = 'expired'\n</code></pre> <code></code> news_recap.ingestion.models.GapStatus.OPEN <code>class-attribute</code> <code>instance-attribute</code> <pre><code>OPEN = 'open'\n</code></pre> <code></code> news_recap.ingestion.models.GapStatus.RESOLVED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>RESOLVED = 'resolved'\n</code></pre> <code></code> news_recap.ingestion.models.GapWrite <code>dataclass</code> <p>Input payload for recording failed source windows.</p> Attributes <code></code> news_recap.ingestion.models.GapWrite.error_code <code>instance-attribute</code> <pre><code>error_code: str\n</code></pre> <code></code> news_recap.ingestion.models.GapWrite.from_cursor_or_time <code>instance-attribute</code> <pre><code>from_cursor_or_time: str | None\n</code></pre> <code></code> news_recap.ingestion.models.GapWrite.retry_after <code>instance-attribute</code> <pre><code>retry_after: int | None\n</code></pre> <code></code> news_recap.ingestion.models.GapWrite.to_cursor_or_time <code>instance-attribute</code> <pre><code>to_cursor_or_time: str | None\n</code></pre> <code></code> news_recap.ingestion.models.GlobalGcResult <code>dataclass</code> <p>Result of global garbage collection for unreferenced shared records.</p> Attributes <code></code> news_recap.ingestion.models.GlobalGcResult.articles_deleted <code>instance-attribute</code> <pre><code>articles_deleted: int\n</code></pre> <code></code> news_recap.ingestion.models.GlobalGcResult.dry_run <code>instance-attribute</code> <pre><code>dry_run: bool\n</code></pre> <code></code> news_recap.ingestion.models.GlobalGcResult.public_resources_deleted <code>instance-attribute</code> <pre><code>public_resources_deleted: int\n</code></pre> <code></code> news_recap.ingestion.models.GlobalGcResult.raw_payloads_deleted <code>instance-attribute</code> <pre><code>raw_payloads_deleted: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap <code>dataclass</code> <p>Failed ingestion window that should be retried.</p> Attributes <code></code> news_recap.ingestion.models.IngestionGap.error_code <code>instance-attribute</code> <pre><code>error_code: str\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.from_cursor_or_time <code>instance-attribute</code> <pre><code>from_cursor_or_time: str | None\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.gap_id <code>instance-attribute</code> <pre><code>gap_id: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.retry_after <code>instance-attribute</code> <pre><code>retry_after: int | None\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.source <code>instance-attribute</code> <pre><code>source: str\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.status <code>instance-attribute</code> <pre><code>status: GapStatus\n</code></pre> <code></code> news_recap.ingestion.models.IngestionGap.to_cursor_or_time <code>instance-attribute</code> <pre><code>to_cursor_or_time: str | None\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters <code>dataclass</code> <p>Counters tracked for ingestion run statistics.</p> Attributes <code></code> news_recap.ingestion.models.IngestionRunCounters.dedup_clusters_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_clusters_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters.dedup_duplicates_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_duplicates_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters.gaps_opened_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gaps_opened_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters.ingested_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ingested_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters.skipped_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>skipped_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunCounters.updated_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView <code>dataclass</code> <p>Compact run view for CLI reporting.</p> Attributes <code></code> news_recap.ingestion.models.IngestionRunView.dedup_clusters_count <code>instance-attribute</code> <pre><code>dedup_clusters_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.dedup_duplicates_count <code>instance-attribute</code> <pre><code>dedup_duplicates_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.finished_at <code>instance-attribute</code> <pre><code>finished_at: datetime | None\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.gaps_opened_count <code>instance-attribute</code> <pre><code>gaps_opened_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.ingested_count <code>instance-attribute</code> <pre><code>ingested_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.run_id <code>instance-attribute</code> <pre><code>run_id: str\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.skipped_count <code>instance-attribute</code> <pre><code>skipped_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.source <code>instance-attribute</code> <pre><code>source: str\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.started_at <code>instance-attribute</code> <pre><code>started_at: datetime\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.status <code>instance-attribute</code> <pre><code>status: str\n</code></pre> <code></code> news_recap.ingestion.models.IngestionRunView.updated_count <code>instance-attribute</code> <pre><code>updated_count: int\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats <code>dataclass</code> <p>Aggregated ingestion counters for a time window.</p> Attributes <code></code> news_recap.ingestion.models.IngestionWindowStats.dedup_clusters_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_clusters_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.dedup_duplicates_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_duplicates_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.failed_runs_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>failed_runs_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.gaps_opened_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gaps_opened_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.ingested_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ingested_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.other_runs_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>other_runs_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.partial_runs_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>partial_runs_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.runs_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>runs_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.skipped_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>skipped_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.succeeded_runs_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>succeeded_runs_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.IngestionWindowStats.updated_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle <code>dataclass</code> <p>Article record ready for persistence.</p> Attributes <code></code> news_recap.ingestion.models.NormalizedArticle.clean_text <code>instance-attribute</code> <pre><code>clean_text: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.clean_text_chars <code>instance-attribute</code> <pre><code>clean_text_chars: int\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.content_raw <code>instance-attribute</code> <pre><code>content_raw: str | None\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.external_id <code>instance-attribute</code> <pre><code>external_id: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.is_full_content <code>instance-attribute</code> <pre><code>is_full_content: bool\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.is_truncated <code>instance-attribute</code> <pre><code>is_truncated: bool\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.language_detected <code>instance-attribute</code> <pre><code>language_detected: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.needs_enrichment <code>instance-attribute</code> <pre><code>needs_enrichment: bool\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.published_at <code>instance-attribute</code> <pre><code>published_at: datetime\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.source_domain <code>instance-attribute</code> <pre><code>source_domain: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.source_name <code>instance-attribute</code> <pre><code>source_name: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.summary_raw <code>instance-attribute</code> <pre><code>summary_raw: str | None\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.url_canonical <code>instance-attribute</code> <pre><code>url_canonical: str\n</code></pre> <code></code> news_recap.ingestion.models.NormalizedArticle.url_hash <code>instance-attribute</code> <pre><code>url_hash: str\n</code></pre> <code></code> news_recap.ingestion.models.RetentionPruneResult <code>dataclass</code> <p>Result of retention cleanup for article-related records.</p> Attributes <code></code> news_recap.ingestion.models.RetentionPruneResult.articles_deleted <code>instance-attribute</code> <pre><code>articles_deleted: int\n</code></pre> <code></code> news_recap.ingestion.models.RetentionPruneResult.cutoff <code>instance-attribute</code> <pre><code>cutoff: datetime\n</code></pre> <code></code> news_recap.ingestion.models.RetentionPruneResult.dry_run <code>instance-attribute</code> <pre><code>dry_run: bool\n</code></pre> <code></code> news_recap.ingestion.models.RetentionPruneResult.private_resources_deleted <code>class-attribute</code> <code>instance-attribute</code> <pre><code>private_resources_deleted: int = 0\n</code></pre> <code></code> news_recap.ingestion.models.RetentionPruneResult.raw_payloads_deleted <code>instance-attribute</code> <pre><code>raw_payloads_deleted: int\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus <p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Lifecycle states for ingestion runs.</p> Attributes <code></code> news_recap.ingestion.models.RunStatus.FAILED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>FAILED = 'failed'\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus.PARTIAL <code>class-attribute</code> <code>instance-attribute</code> <pre><code>PARTIAL = 'partial'\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus.QUEUED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>QUEUED = 'queued'\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus.RUNNING <code>class-attribute</code> <code>instance-attribute</code> <pre><code>RUNNING = 'running'\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus.SUCCEEDED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>SUCCEEDED = 'succeeded'\n</code></pre> <code></code> news_recap.ingestion.models.RunStatus.TIMEOUT <code>class-attribute</code> <code>instance-attribute</code> <pre><code>TIMEOUT = 'timeout'\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle <code>dataclass</code> <p>Normalized article payload from a source connector.</p> Attributes <code></code> news_recap.ingestion.models.SourceArticle.content <code>class-attribute</code> <code>instance-attribute</code> <pre><code>content: str | None = None\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.external_id <code>instance-attribute</code> <pre><code>external_id: str\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.published_at <code>instance-attribute</code> <pre><code>published_at: datetime\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.raw_payload <code>class-attribute</code> <code>instance-attribute</code> <pre><code>raw_payload: dict[str, object] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.source <code>instance-attribute</code> <pre><code>source: str\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.summary <code>class-attribute</code> <code>instance-attribute</code> <pre><code>summary: str | None = None\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.models.SourceArticle.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.ingestion.models.SourcePage <code>dataclass</code> <p>Page of source articles with cursor-based pagination.</p> Attributes <code></code> news_recap.ingestion.models.SourcePage.articles <code>instance-attribute</code> <pre><code>articles: list[SourceArticle]\n</code></pre> <code></code> news_recap.ingestion.models.SourcePage.cursor <code>instance-attribute</code> <pre><code>cursor: str | None\n</code></pre> <code></code> news_recap.ingestion.models.SourcePage.next_cursor <code>instance-attribute</code> <pre><code>next_cursor: str | None\n</code></pre> <code></code> news_recap.ingestion.models.UpsertAction <p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Operation result for article upsert.</p> Attributes <code></code> news_recap.ingestion.models.UpsertAction.INSERTED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>INSERTED = 'inserted'\n</code></pre> <code></code> news_recap.ingestion.models.UpsertAction.SKIPPED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>SKIPPED = 'skipped'\n</code></pre> <code></code> news_recap.ingestion.models.UpsertAction.UPDATED <code>class-attribute</code> <code>instance-attribute</code> <pre><code>UPDATED = 'updated'\n</code></pre> <code></code> news_recap.ingestion.models.UpsertResult <code>dataclass</code> <p>Result of persisting a normalized article.</p> Attributes <code></code> news_recap.ingestion.models.UpsertResult.action <code>instance-attribute</code> <pre><code>action: UpsertAction\n</code></pre> <code></code> news_recap.ingestion.models.UpsertResult.article_id <code>instance-attribute</code> <pre><code>article_id: str\n</code></pre>"},{"location":"reference/#news_recap.ingestion.pipeline","title":"news_recap.ingestion.pipeline","text":"<p>End-to-end ingestion pipeline orchestration.</p> Classes news_recap.ingestion.pipeline.IngestionOrchestrator <p>Coordinates independent ingestion stage services.</p> Attributes news_recap.ingestion.pipeline.IngestionOrchestrator.dedup_stage <code>instance-attribute</code> <pre><code>dedup_stage = DedupStageService(repository=repository, dedup_settings=dedup)\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionOrchestrator.fetch_stage <code>instance-attribute</code> <pre><code>fetch_stage = FetchStageService(source=source, repository=repository, ingestion_settings=ingestion, normalizer=normalizer)\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionOrchestrator.repository <code>instance-attribute</code> <pre><code>repository = repository\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionOrchestrator.settings <code>instance-attribute</code> <pre><code>settings = settings\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionOrchestrator.source <code>instance-attribute</code> <pre><code>source = source\n</code></pre> Functions <code></code> news_recap.ingestion.pipeline.IngestionOrchestrator.run_daily <pre><code>run_daily() -&gt; IngestionSummary\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionSummary <code>dataclass</code> <p>Result of one ingestion pipeline run.</p> Attributes <code></code> news_recap.ingestion.pipeline.IngestionSummary.counters <code>instance-attribute</code> <pre><code>counters: IngestionRunCounters\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionSummary.run_id <code>instance-attribute</code> <pre><code>run_id: str\n</code></pre> <code></code> news_recap.ingestion.pipeline.IngestionSummary.status <code>instance-attribute</code> <pre><code>status: RunStatus\n</code></pre> Functions <code></code> news_recap.ingestion.pipeline.run_daily_ingestion <pre><code>run_daily_ingestion(*, settings: Settings, repository: SQLiteRepository, source: SourceAdapter) -&gt; IngestionSummary\n</code></pre> <p>Run daily ingestion with provided dependencies.</p>"},{"location":"reference/#news_recap.ingestion.repository","title":"news_recap.ingestion.repository","text":"<p>SQLModel-backed storage facade for ingestion pipeline.</p> Attributes news_recap.ingestion.repository.DEFAULT_ACTIVE_RUN_STALE_AFTER <code>module-attribute</code> <pre><code>DEFAULT_ACTIVE_RUN_STALE_AFTER = timedelta(minutes=30)\n</code></pre> <code></code> news_recap.ingestion.repository.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.ingestion.repository.SQLiteRepository <p>Facade that persists ingestion entities using SQLModel and Alembic.</p> Attributes <code></code> news_recap.ingestion.repository.SQLiteRepository.db_path <code>instance-attribute</code> <pre><code>db_path = db_path\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.engine <code>instance-attribute</code> <pre><code>engine = build_sqlite_engine(db_path=db_path, busy_timeout_ms=sqlite_busy_timeout_ms)\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.sqlite_busy_timeout_ms <code>instance-attribute</code> <pre><code>sqlite_busy_timeout_ms = sqlite_busy_timeout_ms\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.user_id <code>instance-attribute</code> <pre><code>user_id = user_id\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.user_name <code>instance-attribute</code> <pre><code>user_name = user_name\n</code></pre> Functions <code></code> news_recap.ingestion.repository.SQLiteRepository.add_output_feedback <pre><code>add_output_feedback(payload: OutputFeedbackWrite) -&gt; None\n</code></pre> <p>Persist feedback against output or block.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.add_read_state_event <pre><code>add_read_state_event(payload: ReadStateEventWrite) -&gt; None\n</code></pre> <p>Persist read/open event for output or output block.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.close <pre><code>close() -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.create_gap <pre><code>create_gap(*, run_id: str, source: str, gap: GapWrite) -&gt; int\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.delete_rss_processing_snapshot <pre><code>delete_rss_processing_snapshot(*, source_name: str, feed_set_hash: str) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.finish_run <pre><code>finish_run(run_id: str, status: RunStatus, counters: IngestionRunCounters, error_summary: str | None = None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.gc_unreferenced_articles <pre><code>gc_unreferenced_articles(*, dry_run: bool = False) -&gt; GlobalGcResult\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_article_resource_for_user <pre><code>get_article_resource_for_user(*, url_hash: str) -&gt; ArticleResource | None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_embeddings <pre><code>get_embeddings(article_ids: list[str], model_name: str) -&gt; dict[str, list[float]]\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_feed_http_cache <pre><code>get_feed_http_cache(*, source_name: str, feed_url: str) -&gt; tuple[str | None, str | None]\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_latest_daily_story_snapshots_before <pre><code>get_latest_daily_story_snapshots_before(*, business_date: date) -&gt; list[DailyStorySnapshotView]\n</code></pre> <p>Return latest prior-day snapshot set for continuity context.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_latest_run_id <pre><code>get_latest_run_id(*, source: str | None = None, since: datetime | None = None) -&gt; str | None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_rss_processing_snapshot <pre><code>get_rss_processing_snapshot(*, source_name: str, feed_set_hash: str) -&gt; tuple[str, str | None, datetime] | None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.get_user_output <pre><code>get_user_output(*, output_id: str) -&gt; UserOutputView | None\n</code></pre> <p>Fetch one output with ordered blocks.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.init_schema <pre><code>init_schema() -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.intelligence_stats_snapshot <pre><code>intelligence_stats_snapshot(*, since: datetime) -&gt; dict[str, int]\n</code></pre> <p>Aggregate domain counters for observability windows.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_candidates_for_dedup <pre><code>list_candidates_for_dedup(since: datetime) -&gt; list[DedupCandidate]\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_clusters_for_run <pre><code>list_clusters_for_run(*, run_id: str, min_size: int = 1, limit: int = 20, members_per_cluster: int = 5) -&gt; ClusterListResult\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_daily_story_snapshots <pre><code>list_daily_story_snapshots(*, business_date: date) -&gt; list[DailyStorySnapshotView]\n</code></pre> <p>List persisted daily snapshots for one date.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_monitor_questions <pre><code>list_monitor_questions(*, include_disabled: bool = False) -&gt; list[MonitorQuestionView]\n</code></pre> <p>List monitor prompts for current user.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_open_gaps <pre><code>list_open_gaps(source: str, limit: int) -&gt; list[IngestionGap]\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_recent_read_source_ids <pre><code>list_recent_read_source_ids(*, days: int = 3) -&gt; set[str]\n</code></pre> <p>Return source ids from output blocks that were marked as viewed/opened recently.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_recent_runs <pre><code>list_recent_runs(*, limit: int = 5, source: str | None = None) -&gt; list[IngestionRunView]\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_story_assignments <pre><code>list_story_assignments(*, business_date: date) -&gt; list[StoryAssignmentView]\n</code></pre> <p>List assignments for one business date.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_story_definitions <pre><code>list_story_definitions(*, include_disabled: bool = False) -&gt; list[StoryDefinitionView]\n</code></pre> <p>List user story definitions ordered by priority.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_user_outputs <pre><code>list_user_outputs(*, kind: str | None = None, business_date: date | None = None, limit: int = 50) -&gt; list[UserOutputView]\n</code></pre> <p>List recent outputs with blocks.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.list_user_retrieval_articles <pre><code>list_user_retrieval_articles(*, limit: int = 20, since: datetime | None = None, until: datetime | None = None, source_ids: tuple[str, ...] | None = None) -&gt; list[SourceCorpusEntry]\n</code></pre> <p>Resolve user-scoped retrieval corpus entries from <code>user_articles</code>.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.prune_articles <pre><code>prune_articles(*, cutoff: datetime, dry_run: bool = False) -&gt; RetentionPruneResult\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.prune_user_private_resources <pre><code>prune_user_private_resources(*, cutoff: datetime, dry_run: bool = False) -&gt; int\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.replace_daily_story_snapshots <pre><code>replace_daily_story_snapshots(*, business_date: date, snapshots: list[DailyStorySnapshotWrite]) -&gt; int\n</code></pre> <p>Replace full daily continuity snapshots for one date.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.replace_story_assignments <pre><code>replace_story_assignments(*, business_date: date, assignments: list[StoryAssignmentWrite]) -&gt; int\n</code></pre> <p>Replace full assignment set for one user/date (idempotent rerun).</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.resolve_gap <pre><code>resolve_gap(gap_id: int) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.save_dedup_clusters <pre><code>save_dedup_clusters(*, run_id: str, model_name: str, threshold: float, clusters: list[DedupCluster]) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.start_run <pre><code>start_run(source: str, *, stale_after: timedelta = DEFAULT_ACTIVE_RUN_STALE_AFTER) -&gt; str\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.summarize_runs <pre><code>summarize_runs(*, since: datetime, until: datetime, source: str | None = None) -&gt; IngestionWindowStats\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.touch_run <pre><code>touch_run(run_id: str) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.update_rss_processing_snapshot_cursor <pre><code>update_rss_processing_snapshot_cursor(*, source_name: str, feed_set_hash: str, next_cursor: str | None) -&gt; bool\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_article <pre><code>upsert_article(article: NormalizedArticle, run_id: str) -&gt; UpsertResult\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_embeddings <pre><code>upsert_embeddings(*, model_name: str, vectors: dict[str, list[float]], ttl_days: int) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_feed_http_cache <pre><code>upsert_feed_http_cache(*, source_name: str, feed_url: str, etag: str | None, last_modified: str | None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_monitor_question <pre><code>upsert_monitor_question(payload: MonitorQuestionWrite) -&gt; MonitorQuestionView\n</code></pre> <p>Create or update monitor prompt definition.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_public_article_resource <pre><code>upsert_public_article_resource(*, url_hash: str, url_canonical: str, fetch_status: str, http_status: int | None = None, content_text: str | None = None, error_code: str | None = None, fetched_at: datetime | None = None, expires_at: datetime | None = None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_raw_article <pre><code>upsert_raw_article(source_name: str, external_id: str, raw_payload: dict[str, object], *, article_id: str | None = None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_rss_processing_snapshot <pre><code>upsert_rss_processing_snapshot(*, source_name: str, feed_set_hash: str, snapshot_json: str, next_cursor: str | None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_story_definition <pre><code>upsert_story_definition(payload: StoryDefinitionWrite) -&gt; StoryDefinitionView\n</code></pre> <p>Create or update pinned story definition.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_user_article_resource <pre><code>upsert_user_article_resource(*, url_hash: str, url_canonical: str, fetch_status: str, http_status: int | None = None, content_text: str | None = None, error_code: str | None = None, fetched_at: datetime | None = None, expires_at: datetime | None = None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.repository.SQLiteRepository.upsert_user_output <pre><code>upsert_user_output(payload: UserOutputUpsert) -&gt; UserOutputView\n</code></pre> <p>Upsert stable business output row and replace its blocks.</p> <code></code> news_recap.ingestion.repository.SQLiteRepository.validate_user_source_ids <pre><code>validate_user_source_ids(*, source_ids: tuple[str, ...]) -&gt; tuple[list[SourceCorpusEntry], list[str]]\n</code></pre> <p>Validate that source IDs belong to current user via <code>user_articles</code>.</p> Functions"},{"location":"reference/#news_recap.ingestion.services","title":"news_recap.ingestion.services","text":"<p>Ingestion services and stages.</p> Modules news_recap.ingestion.services.dedup_service <p>Semantic deduplication stage service.</p> Attributes news_recap.ingestion.services.dedup_service.EMBEDDING_TEXT_VERSION <code>module-attribute</code> <pre><code>EMBEDDING_TEXT_VERSION = 'title-clean-v1'\n</code></pre> Classes <code></code> news_recap.ingestion.services.dedup_service.DedupStageService <p>Runs dedup stage and persists clustering artifacts.</p> Attributes <code></code> news_recap.ingestion.services.dedup_service.DedupStageService.dedup_settings <code>instance-attribute</code> <pre><code>dedup_settings = dedup_settings\n</code></pre> <code></code> news_recap.ingestion.services.dedup_service.DedupStageService.repository <code>instance-attribute</code> <pre><code>repository = repository\n</code></pre> Functions <code></code> news_recap.ingestion.services.dedup_service.DedupStageService.run <pre><code>run(*, run_id: str, counters: IngestionRunCounters) -&gt; None\n</code></pre> Functions <code></code> news_recap.ingestion.services.fetch_service <p>Fetch/backfill stage for ingestion pipeline.</p> Classes <code></code> news_recap.ingestion.services.fetch_service.FetchStageService <p>Fetches source pages, handles gaps, and persists normalized articles.</p> Attributes <code></code> news_recap.ingestion.services.fetch_service.FetchStageService.ingestion_settings <code>instance-attribute</code> <pre><code>ingestion_settings = ingestion_settings\n</code></pre> <code></code> news_recap.ingestion.services.fetch_service.FetchStageService.normalizer <code>instance-attribute</code> <pre><code>normalizer = normalizer\n</code></pre> <code></code> news_recap.ingestion.services.fetch_service.FetchStageService.repository <code>instance-attribute</code> <pre><code>repository = repository\n</code></pre> <code></code> news_recap.ingestion.services.fetch_service.FetchStageService.source <code>instance-attribute</code> <pre><code>source = source\n</code></pre> Functions <code></code> news_recap.ingestion.services.fetch_service.FetchStageService.run <pre><code>run(*, run_id: str, counters: IngestionRunCounters) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.services.fetch_service.SeedCursor <code>dataclass</code> <p>Cursor seed used to process one source chain.</p> Attributes <code></code> news_recap.ingestion.services.fetch_service.SeedCursor.cursor <code>instance-attribute</code> <pre><code>cursor: str | None\n</code></pre> <code></code> news_recap.ingestion.services.fetch_service.SeedCursor.gap_id <code>instance-attribute</code> <pre><code>gap_id: int | None\n</code></pre> <code></code> news_recap.ingestion.services.normalize_service <p>Normalization service for source articles.</p> Classes <code></code> news_recap.ingestion.services.normalize_service.ArticleNormalizationService <p>Converts source payloads into normalized article records.</p> Attributes <code></code> news_recap.ingestion.services.normalize_service.ArticleNormalizationService.ingestion_settings <code>instance-attribute</code> <pre><code>ingestion_settings = ingestion_settings\n</code></pre> <code></code> news_recap.ingestion.services.normalize_service.ArticleNormalizationService.source_name <code>instance-attribute</code> <pre><code>source_name = source_name\n</code></pre> Functions <code></code> news_recap.ingestion.services.normalize_service.ArticleNormalizationService.normalize <pre><code>normalize(source_article: SourceArticle) -&gt; NormalizedArticle\n</code></pre> Functions"},{"location":"reference/#news_recap.ingestion.sources","title":"news_recap.ingestion.sources","text":"<p>Source adapters for ingestion.</p> Modules news_recap.ingestion.sources.base <p>Common source adapter contracts.</p> Classes news_recap.ingestion.sources.base.NonRetryableSourceError <code>dataclass</code> <p>               Bases: <code>SourceError</code></p> <p>Non-retryable source error that should fail the run.</p> Attributes <code></code> news_recap.ingestion.sources.base.NonRetryableSourceError.from_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>from_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.base.NonRetryableSourceError.to_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>to_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.base.PageCheckpointSourceAdapter <p>               Bases: <code>Protocol</code></p> <p>Optional hook to persist page-level progress after successful processing.</p> Functions <code></code> news_recap.ingestion.sources.base.PageCheckpointSourceAdapter.mark_page_processed <pre><code>mark_page_processed(*, next_cursor: str | None) -&gt; None\n</code></pre> <p>Persist progress cursor after one page is fully processed.</p> <code></code> news_recap.ingestion.sources.base.RunLifecycleSourceAdapter <p>               Bases: <code>Protocol</code></p> <p>Optional run lifecycle hook for stateful source adapters.</p> Functions <code></code> news_recap.ingestion.sources.base.RunLifecycleSourceAdapter.begin_run <pre><code>begin_run() -&gt; None\n</code></pre> <p>Reset any source state that must not leak between runs.</p> <code></code> news_recap.ingestion.sources.base.SourceAdapter <p>               Bases: <code>Protocol</code></p> <p>Interface for article sources.</p> Attributes <code></code> news_recap.ingestion.sources.base.SourceAdapter.name <code>instance-attribute</code> <pre><code>name: str\n</code></pre> Functions <code></code> news_recap.ingestion.sources.base.SourceAdapter.fetch_page <pre><code>fetch_page(cursor: str | None, limit: int) -&gt; SourcePage\n</code></pre> <p>Fetch one page from the source by cursor.</p> <code></code> news_recap.ingestion.sources.base.SourceError <code>dataclass</code> <p>               Bases: <code>Exception</code></p> <p>Base source fetch error.</p> Attributes <code></code> news_recap.ingestion.sources.base.SourceError.code <code>class-attribute</code> <code>instance-attribute</code> <pre><code>code: str = 'source_error'\n</code></pre> <code></code> news_recap.ingestion.sources.base.SourceError.message <code>instance-attribute</code> <pre><code>message: str\n</code></pre> <code></code> news_recap.ingestion.sources.base.TemporarySourceError <code>dataclass</code> <p>               Bases: <code>SourceError</code></p> <p>Retryable source error with cursor context.</p> Attributes <code></code> news_recap.ingestion.sources.base.TemporarySourceError.from_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>from_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.base.TemporarySourceError.retry_after <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_after: int | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.base.TemporarySourceError.to_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>to_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.rss <p>Generic RSS/Atom source adapter.</p> Attributes <code></code> news_recap.ingestion.sources.rss.HTTP_NOT_MODIFIED <code>module-attribute</code> <pre><code>HTTP_NOT_MODIFIED = 304\n</code></pre> <code></code> news_recap.ingestion.sources.rss.INOREADER_HOST_SUFFIX <code>module-attribute</code> <pre><code>INOREADER_HOST_SUFFIX = 'inoreader.com'\n</code></pre> <code></code> news_recap.ingestion.sources.rss.INOREADER_STREAM_PATH_PART <code>module-attribute</code> <pre><code>INOREADER_STREAM_PATH_PART = '/stream/'\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RETRYABLE_HTTP_STATUS_CODES <code>module-attribute</code> <pre><code>RETRYABLE_HTTP_STATUS_CODES = frozenset({429, 500, 502, 503, 504})\n</code></pre> <code></code> news_recap.ingestion.sources.rss.UNKNOWN_PUBLISHED_AT <code>module-attribute</code> <pre><code>UNKNOWN_PUBLISHED_AT = datetime(1970, 1, 1, tzinfo=UTC)\n</code></pre> <code></code> news_recap.ingestion.sources.rss.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats <code>dataclass</code> <p>Per-feed HTTP conditional fetch diagnostics for one run.</p> Attributes <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.feed_url <code>instance-attribute</code> <pre><code>feed_url: str\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.received_etag <code>instance-attribute</code> <pre><code>received_etag: bool\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.received_items <code>instance-attribute</code> <pre><code>received_items: int\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.received_last_modified <code>instance-attribute</code> <pre><code>received_last_modified: bool\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.request_url <code>instance-attribute</code> <pre><code>request_url: str\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.requested_n <code>instance-attribute</code> <pre><code>requested_n: int\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.sent_if_modified_since <code>instance-attribute</code> <pre><code>sent_if_modified_since: bool\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.sent_if_none_match <code>instance-attribute</code> <pre><code>sent_if_none_match: bool\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedFetchStats.status <code>instance-attribute</code> <pre><code>status: str\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFeedStateStore <p>               Bases: <code>Protocol</code></p> <p>Persistence contract for HTTP cache validators per feed URL.</p> Functions <code></code> news_recap.ingestion.sources.rss.RssFeedStateStore.get_feed_http_cache <pre><code>get_feed_http_cache(*, source_name: str, feed_url: str) -&gt; tuple[str | None, str | None]\n</code></pre> <p>Return persisted (etag, last_modified) validators for a feed.</p> <code></code> news_recap.ingestion.sources.rss.RssFeedStateStore.upsert_feed_http_cache <pre><code>upsert_feed_http_cache(*, source_name: str, feed_url: str, etag: str | None, last_modified: str | None) -&gt; None\n</code></pre> <p>Persist latest (etag, last_modified) validators for a feed.</p> <code></code> news_recap.ingestion.sources.rss.RssFetchResponse <code>dataclass</code> <p>HTTP response metadata for one RSS request.</p> Attributes <code></code> news_recap.ingestion.sources.rss.RssFetchResponse.etag <code>class-attribute</code> <code>instance-attribute</code> <pre><code>etag: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFetchResponse.last_modified <code>class-attribute</code> <code>instance-attribute</code> <pre><code>last_modified: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFetchResponse.not_modified <code>class-attribute</code> <code>instance-attribute</code> <pre><code>not_modified: bool = False\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssFetchResponse.raw_xml <code>instance-attribute</code> <pre><code>raw_xml: str | None\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssProcessingSnapshotStore <p>               Bases: <code>Protocol</code></p> <p>Persistence contract for crash-safe RSS processing snapshots.</p> Functions <code></code> news_recap.ingestion.sources.rss.RssProcessingSnapshotStore.delete_rss_processing_snapshot <pre><code>delete_rss_processing_snapshot(*, source_name: str, feed_set_hash: str) -&gt; None\n</code></pre> <p>Delete snapshot after full processing is complete.</p> <code></code> news_recap.ingestion.sources.rss.RssProcessingSnapshotStore.get_rss_processing_snapshot <pre><code>get_rss_processing_snapshot(*, source_name: str, feed_set_hash: str) -&gt; tuple[str, str | None, datetime] | None\n</code></pre> <p>Return (snapshot_json, next_cursor, updated_at) if a pending snapshot exists.</p> <code></code> news_recap.ingestion.sources.rss.RssProcessingSnapshotStore.update_rss_processing_snapshot_cursor <pre><code>update_rss_processing_snapshot_cursor(*, source_name: str, feed_set_hash: str, next_cursor: str | None) -&gt; bool\n</code></pre> <p>Update snapshot cursor after one processed page.</p> <code></code> news_recap.ingestion.sources.rss.RssProcessingSnapshotStore.upsert_rss_processing_snapshot <pre><code>upsert_rss_processing_snapshot(*, source_name: str, feed_set_hash: str, snapshot_json: str, next_cursor: str | None) -&gt; None\n</code></pre> <p>Create or replace pending snapshot content and cursor.</p> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats <code>dataclass</code> <p>Aggregated RSS fetch diagnostics for one run.</p> Attributes <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.feeds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feeds: list[RssFeedFetchStats] = field(default_factory=list)\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.feeds_total <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feeds_total: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.requests_conditional <code>class-attribute</code> <code>instance-attribute</code> <pre><code>requests_conditional: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.responses_fetched <code>class-attribute</code> <code>instance-attribute</code> <pre><code>responses_fetched: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.responses_not_modified <code>class-attribute</code> <code>instance-attribute</code> <pre><code>responses_not_modified: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.responses_with_etag <code>class-attribute</code> <code>instance-attribute</code> <pre><code>responses_with_etag: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.responses_with_last_modified <code>class-attribute</code> <code>instance-attribute</code> <pre><code>responses_with_last_modified: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.resume_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>resume_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.snapshot_articles <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_articles: int = 0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.snapshot_expired <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_expired: bool = False\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssRunFetchStats.snapshot_restored <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_restored: bool = False\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSource <p>               Bases: <code>PageCheckpointSourceAdapter</code></p> <p>Cursor-based source over one or more RSS/Atom feeds.</p> Attributes <code></code> news_recap.ingestion.sources.rss.RssSource.config <code>instance-attribute</code> <pre><code>config = config\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSource.name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>name = 'rss'\n</code></pre> Functions <code></code> news_recap.ingestion.sources.rss.RssSource.begin_run <pre><code>begin_run() -&gt; None\n</code></pre> <p>Reset run-local snapshot state before a new ingestion run.</p> <code></code> news_recap.ingestion.sources.rss.RssSource.fetch_page <pre><code>fetch_page(cursor: str | None, limit: int) -&gt; SourcePage\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSource.get_last_run_fetch_stats <pre><code>get_last_run_fetch_stats() -&gt; RssRunFetchStats\n</code></pre> <p>Return HTTP fetch diagnostics for the latest run.</p> <code></code> news_recap.ingestion.sources.rss.RssSource.mark_page_processed <pre><code>mark_page_processed(*, next_cursor: str | None) -&gt; None\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig <code>dataclass</code> <p>RSS source settings.</p> Attributes <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.default_items_per_feed <code>class-attribute</code> <code>instance-attribute</code> <pre><code>default_items_per_feed: int = 10000\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.feed_urls <code>instance-attribute</code> <pre><code>feed_urls: tuple[str, ...]\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.max_retries <code>class-attribute</code> <code>instance-attribute</code> <pre><code>max_retries: int = 3\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.per_feed_items <code>class-attribute</code> <code>instance-attribute</code> <pre><code>per_feed_items: dict[str, int] = field(default_factory=dict)\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.request_timeout_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>request_timeout_seconds: float = 30.0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.retry_backoff_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_backoff_seconds: float = 1.0\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.snapshot_max_age_seconds <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_max_age_seconds: int | None = 24 * 3600\n</code></pre> <code></code> news_recap.ingestion.sources.rss.RssSourceConfig.state_store <code>class-attribute</code> <code>instance-attribute</code> <pre><code>state_store: RssFeedStateStore | RssProcessingSnapshotStore | None = None\n</code></pre>"},{"location":"reference/#news_recap.ingestion.storage","title":"news_recap.ingestion.storage","text":"<p>Storage layer for ingestion pipeline.</p> Modules news_recap.ingestion.storage.alembic_runner <p>Utilities to run Alembic migrations programmatically.</p> Functions news_recap.ingestion.storage.alembic_runner.upgrade_head <pre><code>upgrade_head(db_path: Path) -&gt; None\n</code></pre> <p>Apply Alembic migrations up to head for the given SQLite database.</p> <code></code> news_recap.ingestion.storage.common <p>Common helpers for storage repositories.</p> Functions <code></code> news_recap.ingestion.storage.common.build_sqlite_engine <pre><code>build_sqlite_engine(*, db_path: Path, busy_timeout_ms: int) -&gt; Engine\n</code></pre> <p>Build SQLAlchemy engine with consistent SQLite policy.</p> <code></code> news_recap.ingestion.storage.common.connect_sqlite <pre><code>connect_sqlite(db_path: str) -&gt; Connection\n</code></pre> <p>Create sqlite connection configured for row access by name.</p> <code></code> news_recap.ingestion.storage.common.connect_sqlite_with_policy <pre><code>connect_sqlite_with_policy(*, db_path: Path, busy_timeout_ms: int) -&gt; Connection\n</code></pre> <p>Create sqlite3 connection with the same policy as SQLAlchemy engine.</p> <code></code> news_recap.ingestion.storage.common.from_iso <pre><code>from_iso(value: str) -&gt; datetime\n</code></pre> <p>Parse ISO datetime and ensure timezone-aware UTC fallback.</p> <code></code> news_recap.ingestion.storage.common.utc_now <pre><code>utc_now() -&gt; datetime\n</code></pre> <p>Current UTC timestamp.</p> <code></code> news_recap.ingestion.storage.sqlmodel_models <p>SQLModel ORM tables for ingestion storage.</p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.DEFAULT_USER_ID <code>module-attribute</code> <pre><code>DEFAULT_USER_ID = 'default_user'\n</code></pre> Classes <code></code> news_recap.ingestion.storage.sqlmodel_models.AppUser <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.AppUser.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.AppUser.display_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>display_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.AppUser.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(primary_key=True, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.clean_text <code>class-attribute</code> <code>instance-attribute</code> <pre><code>clean_text: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.clean_text_chars <code>instance-attribute</code> <pre><code>clean_text_chars: int\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.content_raw <code>class-attribute</code> <code>instance-attribute</code> <pre><code>content_raw: str | None = Field(default=None, sa_column=Column(Text))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.external_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>external_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.fallback_key <code>class-attribute</code> <code>instance-attribute</code> <pre><code>fallback_key: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.ingested_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ingested_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.is_full_content <code>instance-attribute</code> <pre><code>is_full_content: bool\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.is_truncated <code>instance-attribute</code> <pre><code>is_truncated: bool\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.language_detected <code>class-attribute</code> <code>instance-attribute</code> <pre><code>language_detected: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.last_processed_run_id <code>instance-attribute</code> <pre><code>last_processed_run_id: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.published_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>published_at: datetime = Field(sa_column=Column(DateTime(timezone=True), index=True, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.source_domain <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_domain: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.source_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.summary_raw <code>class-attribute</code> <code>instance-attribute</code> <pre><code>summary_raw: str | None = Field(default=None, sa_column=Column(Text))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.url_canonical <code>instance-attribute</code> <pre><code>url_canonical: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.Article.url_hash <code>class-attribute</code> <code>instance-attribute</code> <pre><code>url_hash: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(foreign_key='articles.article_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.cluster_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>cluster_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.is_representative <code>instance-attribute</code> <pre><code>is_representative: bool\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.run_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>run_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.similarity_to_rep <code>instance-attribute</code> <pre><code>similarity_to_rep: float\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleDedup.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(foreign_key='articles.article_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.embedding_blob <code>class-attribute</code> <code>instance-attribute</code> <pre><code>embedding_blob: bytes = Field(sa_column=Column(LargeBinary, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.embedding_dim <code>instance-attribute</code> <pre><code>embedding_dim: int\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.expires_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>expires_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True), index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleEmbedding.model_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>model_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(foreign_key='articles.article_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.external_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>external_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.is_primary <code>class-attribute</code> <code>instance-attribute</code> <pre><code>is_primary: bool = False\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleExternalId.source_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(foreign_key='articles.article_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.external_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>external_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.first_seen_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>first_seen_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.raw_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>raw_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleRaw.source_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.content_text <code>class-attribute</code> <code>instance-attribute</code> <pre><code>content_text: str | None = Field(default=None, sa_column=Column(Text))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.error_code <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error_code: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.expires_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>expires_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True), index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.fetch_status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>fetch_status: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.fetched_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>fetched_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True)))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.http_status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>http_status: int | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.url_canonical <code>instance-attribute</code> <pre><code>url_canonical: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.url_hash <code>class-attribute</code> <code>instance-attribute</code> <pre><code>url_hash: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ArticleResource.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str | None = Field(default=None, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.business_date <code>class-attribute</code> <code>instance-attribute</code> <pre><code>business_date: date = Field(sa_column=Column(Date, nullable=False, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.continuity_key <code>class-attribute</code> <code>instance-attribute</code> <pre><code>continuity_key: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.story_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.story_key <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_key: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.summary_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>summary_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.title <code>instance-attribute</code> <pre><code>title: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DailyStorySnapshot.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.alt_sources_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>alt_sources_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.cluster_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>cluster_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.model_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>model_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.representative_article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>representative_article_id: str = Field(foreign_key='articles.article_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.run_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>run_id: str = Field(foreign_key='ingestion_runs.run_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.threshold <code>instance-attribute</code> <pre><code>threshold: float\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.DedupCluster.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.error_code <code>instance-attribute</code> <pre><code>error_code: str\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.from_cursor_or_time <code>class-attribute</code> <code>instance-attribute</code> <pre><code>from_cursor_or_time: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.gap_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gap_id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.resolved_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>resolved_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True)))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.retry_after <code>class-attribute</code> <code>instance-attribute</code> <pre><code>retry_after: int | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.run_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>run_id: str = Field(foreign_key='ingestion_runs.run_id', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.source <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>status: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.to_cursor_or_time <code>class-attribute</code> <code>instance-attribute</code> <pre><code>to_cursor_or_time: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionGap.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.dedup_clusters_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_clusters_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.dedup_duplicates_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>dedup_duplicates_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.error_summary <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error_summary: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.finished_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>finished_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True)))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.gaps_opened_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>gaps_opened_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.heartbeat_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>heartbeat_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True), nullable=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.ingested_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ingested_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.run_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>run_id: str = Field(primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.skipped_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>skipped_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.source <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.started_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>started_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>status: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.updated_count <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_count: int = 0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.IngestionRun.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.cadence <code>class-attribute</code> <code>instance-attribute</code> <pre><code>cadence: str = Field(default='daily', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.enabled <code>class-attribute</code> <code>instance-attribute</code> <pre><code>enabled: bool = Field(default=True, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.monitor_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>monitor_id: str = Field(primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.prompt <code>class-attribute</code> <code>instance-attribute</code> <pre><code>prompt: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.MonitorQuestion.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.details_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>details_json: str | None = Field(default=None, sa_column=Column(Text))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.feedback_type <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feedback_type: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.output_block_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_block_id: int | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.output_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.OutputFeedback.value <code>class-attribute</code> <code>instance-attribute</code> <pre><code>value: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.details_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>details_json: str | None = Field(default=None, sa_column=Column(Text))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.event_type <code>class-attribute</code> <code>instance-attribute</code> <pre><code>event_type: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.output_block_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_block_id: int | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.output_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.ReadStateEvent.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.etag <code>class-attribute</code> <code>instance-attribute</code> <pre><code>etag: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.feed_url <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feed_url: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.last_modified <code>class-attribute</code> <code>instance-attribute</code> <pre><code>last_modified: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.source_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssFeedState.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.feed_set_hash <code>class-attribute</code> <code>instance-attribute</code> <pre><code>feed_set_hash: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.next_cursor <code>class-attribute</code> <code>instance-attribute</code> <pre><code>next_cursor: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.snapshot_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>snapshot_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.source_name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.RssProcessingSnapshot.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(sa_column=Column(ForeignKey('articles.article_id', ondelete='CASCADE'), nullable=False, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.assignment_type <code>class-attribute</code> <code>instance-attribute</code> <pre><code>assignment_type: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.business_date <code>class-attribute</code> <code>instance-attribute</code> <pre><code>business_date: date = Field(sa_column=Column(Date, nullable=False, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.score <code>class-attribute</code> <code>instance-attribute</code> <pre><code>score: float = 0.0\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.story_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.story_key <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_key: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.StoryAssignment.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle.article_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>article_id: str = Field(sa_column=Column(ForeignKey('articles.article_id', ondelete='CASCADE'), nullable=False, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle.deleted_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>deleted_at: datetime | None = Field(default=None, sa_column=Column(DateTime(timezone=True)))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle.discovered_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>discovered_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle.state <code>class-attribute</code> <code>instance-attribute</code> <pre><code>state: str = Field(default='active', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserArticle.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.business_date <code>class-attribute</code> <code>instance-attribute</code> <pre><code>business_date: date = Field(default_factory=lambda: date(), sa_column=Column(Date, nullable=False, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.kind <code>class-attribute</code> <code>instance-attribute</code> <pre><code>kind: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.monitor_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>monitor_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.output_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_id: str = Field(primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.payload_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>payload_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.request_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>request_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>status: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.story_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.task_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>task_id: str | None = Field(default=None, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.title <code>class-attribute</code> <code>instance-attribute</code> <pre><code>title: str | None = None\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutput.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.block_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>block_id: int | None = Field(default=None, primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.block_order <code>class-attribute</code> <code>instance-attribute</code> <pre><code>block_order: int = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.output_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>output_id: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.source_ids_json <code>class-attribute</code> <code>instance-attribute</code> <pre><code>source_ids_json: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.text <code>class-attribute</code> <code>instance-attribute</code> <pre><code>text: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserOutputBlock.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition <p>               Bases: <code>SQLModel</code></p> Attributes <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.created_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>created_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.description <code>class-attribute</code> <code>instance-attribute</code> <pre><code>description: str = Field(sa_column=Column(Text, nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.enabled <code>class-attribute</code> <code>instance-attribute</code> <pre><code>enabled: bool = Field(default=True, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.name <code>class-attribute</code> <code>instance-attribute</code> <pre><code>name: str = Field(index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.priority <code>class-attribute</code> <code>instance-attribute</code> <pre><code>priority: int = Field(default=100, index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.story_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>story_id: str = Field(primary_key=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.target_language <code>class-attribute</code> <code>instance-attribute</code> <pre><code>target_language: str = Field(default='en', index=True)\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.updated_at <code>class-attribute</code> <code>instance-attribute</code> <pre><code>updated_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n</code></pre> <code></code> news_recap.ingestion.storage.sqlmodel_models.UserStoryDefinition.user_id <code>class-attribute</code> <code>instance-attribute</code> <pre><code>user_id: str = Field(default=DEFAULT_USER_ID, sa_column=Column(ForeignKey('users.user_id', ondelete='CASCADE'), nullable=False, server_default=DEFAULT_USER_ID, index=True))\n</code></pre>"},{"location":"reference/#news_recap.main","title":"news_recap.main","text":"<p>CLI entrypoint for news-recap.</p>"},{"location":"reference/#news_recap.main-attributes","title":"Attributes","text":""},{"location":"reference/#news_recap.main.INGESTION_CONTROLLER","title":"news_recap.main.INGESTION_CONTROLLER  <code>module-attribute</code>","text":"<pre><code>INGESTION_CONTROLLER = IngestionCliController()\n</code></pre>"},{"location":"reference/#news_recap.main.INTELLIGENCE_CONTROLLER","title":"news_recap.main.INTELLIGENCE_CONTROLLER  <code>module-attribute</code>","text":"<pre><code>INTELLIGENCE_CONTROLLER = IntelligenceCliController()\n</code></pre>"},{"location":"reference/#news_recap.main.RECAP_CONTROLLER","title":"news_recap.main.RECAP_CONTROLLER  <code>module-attribute</code>","text":"<pre><code>RECAP_CONTROLLER = RecapCliController()\n</code></pre>"},{"location":"reference/#news_recap.main-classes","title":"Classes","text":""},{"location":"reference/#news_recap.main-functions","title":"Functions","text":""},{"location":"reference/#news_recap.main.feedback","title":"news_recap.main.feedback","text":"<pre><code>feedback() -&gt; None\n</code></pre> <p>Feedback commands for outputs and blocks.</p>"},{"location":"reference/#news_recap.main.feedback_add","title":"news_recap.main.feedback_add","text":"<pre><code>feedback_add(db_path: Path | None, output_id: str, feedback_type: str, value: str | None, output_block_id: int | None) -&gt; None\n</code></pre> <p>Attach feedback to an output or one block.</p>"},{"location":"reference/#news_recap.main.highlights_generate","title":"news_recap.main.highlights_generate","text":"<pre><code>highlights_generate(db_path: Path | None, business_date: datetime | None, priority: int, agent: str | None, model_profile: str | None, model: str | None, max_attempts: int, timeout_seconds: int) -&gt; None\n</code></pre> <p>Generate highlights for one business date.</p>"},{"location":"reference/#news_recap.main.highlights_group","title":"news_recap.main.highlights_group","text":"<pre><code>highlights_group() -&gt; None\n</code></pre> <p>Highlights generation commands.</p>"},{"location":"reference/#news_recap.main.ingest","title":"news_recap.main.ingest","text":"<pre><code>ingest() -&gt; None\n</code></pre> <p>Ingestion commands.</p>"},{"location":"reference/#news_recap.main.ingest_clusters","title":"news_recap.main.ingest_clusters","text":"<pre><code>ingest_clusters(db_path: Path | None, run_id: str | None, source: str | None, hours: int, limit: int, min_size: int, members_per_cluster: int, show_members: bool) -&gt; None\n</code></pre> <p>Show dedup cluster sizes for one run.</p>"},{"location":"reference/#news_recap.main.ingest_daily","title":"news_recap.main.ingest_daily","text":"<pre><code>ingest_daily(db_path: Path | None, feed_urls: tuple[str, ...]) -&gt; None\n</code></pre> <p>Run one daily ingestion cycle from RSS feeds.</p>"},{"location":"reference/#news_recap.main.ingest_duplicates","title":"news_recap.main.ingest_duplicates","text":"<pre><code>ingest_duplicates(db_path: Path | None, run_id: str | None, source: str | None, hours: int, limit_clusters: int, members_per_cluster: int) -&gt; None\n</code></pre> <p>Show sample articles recognized as duplicates (cluster size &gt;= 2).</p>"},{"location":"reference/#news_recap.main.ingest_gc","title":"news_recap.main.ingest_gc","text":"<pre><code>ingest_gc(db_path: Path | None, dry_run: bool) -&gt; None\n</code></pre> <p>Run global GC for shared unreferenced records.</p>"},{"location":"reference/#news_recap.main.ingest_prune","title":"news_recap.main.ingest_prune","text":"<pre><code>ingest_prune(db_path: Path | None, days: int | None, dry_run: bool) -&gt; None\n</code></pre> <p>Delete old articles according to retention policy.</p>"},{"location":"reference/#news_recap.main.ingest_stats","title":"news_recap.main.ingest_stats","text":"<pre><code>ingest_stats(db_path: Path | None, hours: int, source: str | None, recent_runs: int) -&gt; None\n</code></pre> <p>Show ingestion and dedup statistics for a time window.</p>"},{"location":"reference/#news_recap.main.insights_group","title":"news_recap.main.insights_group","text":"<pre><code>insights_group() -&gt; None\n</code></pre> <p>Observability and output inspection commands.</p>"},{"location":"reference/#news_recap.main.insights_outputs","title":"news_recap.main.insights_outputs","text":"<pre><code>insights_outputs(db_path: Path | None, kind: str | None, business_date: datetime | None, limit: int) -&gt; None\n</code></pre> <p>List persisted business outputs.</p>"},{"location":"reference/#news_recap.main.insights_stats","title":"news_recap.main.insights_stats","text":"<pre><code>insights_stats(db_path: Path | None, hours: int) -&gt; None\n</code></pre> <p>Show domain counters for stories/outputs/engagement.</p>"},{"location":"reference/#news_recap.main.monitors","title":"news_recap.main.monitors","text":"<pre><code>monitors() -&gt; None\n</code></pre> <p>Monitor management and execution commands.</p>"},{"location":"reference/#news_recap.main.monitors_define","title":"news_recap.main.monitors_define","text":"<pre><code>monitors_define(db_path: Path | None, monitor_id: str | None, name: str, prompt: str, cadence: str, enabled: bool) -&gt; None\n</code></pre> <p>Create or update one monitor definition.</p>"},{"location":"reference/#news_recap.main.monitors_list","title":"news_recap.main.monitors_list","text":"<pre><code>monitors_list(db_path: Path | None, include_disabled: bool) -&gt; None\n</code></pre> <p>List monitor definitions.</p>"},{"location":"reference/#news_recap.main.monitors_run","title":"news_recap.main.monitors_run","text":"<pre><code>monitors_run(db_path: Path | None, business_date: datetime | None, priority: int, agent: str | None, model_profile: str | None, model: str | None, max_attempts: int, timeout_seconds: int) -&gt; None\n</code></pre> <p>Run enabled monitors and return answers.</p>"},{"location":"reference/#news_recap.main.news_recap","title":"news_recap.main.news_recap","text":"<pre><code>news_recap() -&gt; None\n</code></pre> <p>News recap CLI.</p>"},{"location":"reference/#news_recap.main.qa","title":"news_recap.main.qa","text":"<pre><code>qa() -&gt; None\n</code></pre> <p>Ad-hoc question answering commands.</p>"},{"location":"reference/#news_recap.main.qa_ask","title":"news_recap.main.qa_ask","text":"<pre><code>qa_ask(db_path: Path | None, prompt: str, lookback_days: int | None, priority: int, agent: str | None, model_profile: str | None, model: str | None, max_attempts: int, timeout_seconds: int) -&gt; None\n</code></pre> <p>Run ad-hoc QA with bounded N-day retrieval.</p>"},{"location":"reference/#news_recap.main.read_state_group","title":"news_recap.main.read_state_group","text":"<pre><code>read_state_group() -&gt; None\n</code></pre> <p>Read/open interaction tracking commands.</p>"},{"location":"reference/#news_recap.main.read_state_mark","title":"news_recap.main.read_state_mark","text":"<pre><code>read_state_mark(db_path: Path | None, output_id: str, event_type: str, output_block_id: int | None) -&gt; None\n</code></pre> <p>Record a read/open interaction for output (or output block).</p>"},{"location":"reference/#news_recap.main.recap","title":"news_recap.main.recap","text":"<pre><code>recap() -&gt; None\n</code></pre> <p>News digest pipeline commands.</p>"},{"location":"reference/#news_recap.main.recap_run","title":"news_recap.main.recap_run","text":"<pre><code>recap_run(db_path: Path | None, business_date: datetime | None, agent: str | None) -&gt; None\n</code></pre> <p>Run the full news digest pipeline.</p>"},{"location":"reference/#news_recap.main.stories","title":"news_recap.main.stories","text":"<pre><code>stories() -&gt; None\n</code></pre> <p>Story definition and assignment commands.</p>"},{"location":"reference/#news_recap.main.stories_build","title":"news_recap.main.stories_build","text":"<pre><code>stories_build(db_path: Path | None, business_date: datetime | None) -&gt; None\n</code></pre> <p>Build pinned + auto story assignments for one business date.</p>"},{"location":"reference/#news_recap.main.stories_define","title":"news_recap.main.stories_define","text":"<pre><code>stories_define(db_path: Path | None, story_id: str | None, name: str, description: str, target_language: str, priority: int, enabled: bool) -&gt; None\n</code></pre> <p>Create or update one pinned story definition.</p>"},{"location":"reference/#news_recap.main.stories_list","title":"news_recap.main.stories_list","text":"<pre><code>stories_list(db_path: Path | None, include_disabled: bool) -&gt; None\n</code></pre> <p>List pinned story definitions.</p>"},{"location":"reference/#news_recap.main.story_details_generate","title":"news_recap.main.story_details_generate","text":"<pre><code>story_details_generate(db_path: Path | None, story_id: str, business_date: datetime | None, priority: int, agent: str | None, model_profile: str | None, model: str | None, max_attempts: int, timeout_seconds: int) -&gt; None\n</code></pre> <p>Generate detailed update for one pinned story.</p>"},{"location":"reference/#news_recap.main.story_details_group","title":"news_recap.main.story_details_group","text":"<pre><code>story_details_group() -&gt; None\n</code></pre> <p>Detailed per-story generation commands.</p>"},{"location":"reference/#news_recap.recap","title":"news_recap.recap","text":"<p>News recap pipeline \u2014 filtering, grouping, synthesis, and composition.</p>"},{"location":"reference/#news_recap.recap-modules","title":"Modules","text":""},{"location":"reference/#news_recap.recap.controllers","title":"news_recap.recap.controllers","text":"<p>CLI controller for recap pipeline commands.</p> Attributes news_recap.recap.controllers.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.recap.controllers.RecapCliController <p>CLI controller for recap pipeline operations.</p> Functions <code></code> news_recap.recap.controllers.RecapCliController.run_pipeline <pre><code>run_pipeline(command: RecapRunCommand) -&gt; Iterator[str]\n</code></pre> <p>Execute the full recap pipeline, yielding real-time progress lines.</p> <code></code> news_recap.recap.controllers.RecapRunCommand <code>dataclass</code> <p>Input for recap run CLI command.</p> Attributes <code></code> news_recap.recap.controllers.RecapRunCommand.agent_override <code>class-attribute</code> <code>instance-attribute</code> <pre><code>agent_override: str | None = None\n</code></pre> <code></code> news_recap.recap.controllers.RecapRunCommand.business_date <code>class-attribute</code> <code>instance-attribute</code> <pre><code>business_date: date | None = None\n</code></pre> <code></code> news_recap.recap.controllers.RecapRunCommand.db_path <code>class-attribute</code> <code>instance-attribute</code> <pre><code>db_path: Path | None = None\n</code></pre> Functions"},{"location":"reference/#news_recap.recap.prefect_flow","title":"news_recap.recap.prefect_flow","text":"<p>Prefect-based recap pipeline flow.</p> <p>Replaces the legacy enqueue -&gt; worker-thread -&gt; poll loop with direct agent subprocess execution wrapped in Prefect tasks.  Business-logic helpers (article parsing, event building, etc.) are reused from <code>runner.py</code>.</p> Attributes <code></code> news_recap.recap.prefect_flow.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes Functions <code></code> news_recap.recap.prefect_flow.recap_flow <pre><code>recap_flow(*, business_date: date, preferences: UserPreferences, articles: list[SourceCorpusEntry], workdir_root: Path, routing_defaults: RoutingDefaults, resource_loader: ResourceLoader | None = None, agent_override: str | None = None, on_progress: Callable[[str], None] | None = None) -&gt; PipelineRunResult\n</code></pre> <p>Execute the full recap pipeline as a Prefect flow.</p> <p>Each LLM step runs as a Prefect task with automatic retry. Agent subprocesses are called directly via <code>CliAgentBackend</code> \u2014 no task-queue, no worker threads, no polling.</p> <code></code> news_recap.recap.prefect_flow.run_agent_step <pre><code>run_agent_step(*, step_name: str, workdir_mgr: TaskWorkdirManager, routing_defaults: RoutingDefaults, article_entries: list[ArticleIndexEntry], preferences: UserPreferences, extra_input_files: dict[str, bytes | str] | None = None, agent_override: str | None = None, timeout_seconds: int = _STEP_TIMEOUT, emit: Callable[[str], None] = lambda _: None) -&gt; str\n</code></pre> <p>Execute one LLM pipeline step via agent subprocess.</p> <p>Materializes workdir, resolves routing, calls <code>CliAgentBackend</code> directly (no task-queue, no polling).  Returns the task_id used to locate outputs.</p>"},{"location":"reference/#news_recap.recap.prompts","title":"news_recap.recap.prompts","text":"<p>Prompt templates for each recap pipeline step.</p> Attributes news_recap.recap.prompts.PROMPTS_BY_TASK_TYPE <code>module-attribute</code> <pre><code>PROMPTS_BY_TASK_TYPE: dict[str, str] = {'recap_classify': RECAP_CLASSIFY_PROMPT, 'recap_enrich': RECAP_ENRICH_PROMPT, 'recap_group': RECAP_GROUP_PROMPT, 'recap_enrich_full': RECAP_ENRICH_FULL_PROMPT, 'recap_synthesize': RECAP_SYNTHESIZE_PROMPT, 'recap_compose': RECAP_COMPOSE_PROMPT}\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_CLASSIFY_PROMPT <code>module-attribute</code> <pre><code>RECAP_CLASSIFY_PROMPT = 'You are a news editor deciding which headlines to keep for a daily digest.\\n\\nTwo reference files describe your editorial policy:\\n- input/_discard.txt \u2014 describes categories of stories to discard\\n- input/_priority.txt \u2014 describes categories where the reader wants deeper coverage\\n\\nThese are topic descriptions, not keyword lists. A headline may relate to a\\ndescribed category even without sharing any exact words with the description.\\nRead these files carefully and understand the editorial intent behind each category.\\n\\nHeadline files are in input/resources/ as {{id}}_in.txt (one headline per file).\\n\\nFor each headline, read it and reason: what real-world story does this headline\\nrefer to? Then decide:\\n\\n1. Is the headline clear enough that you can tell what the story is about\\n   and whether it relates to any category described in DISCARD or PRIORITY?\\n   If you cannot tell \u2192 verdict is \"enrich\" (headline needs rewriting).\\n\\n2. Can the story be attributed to any category described in _discard.txt?\\n   If yes \u2192 verdict is \"trash\".\\n\\n3. Otherwise \u2192 verdict is \"ok\".\\n   PRIORITY categories are NOT a filter. They indicate where the reader wants\\n   extra detail later. Keep all world news that does not match DISCARD.\\n\\nWrite each verdict (one word: ok, enrich, or trash) to output/results/{{id}}_out.txt.\\nProcess every headline file.\\n'\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_COMPOSE_PROMPT <code>module-attribute</code> <pre><code>RECAP_COMPOSE_PROMPT = 'You are composing the final daily news digest from synthesized events.\\n\\nFor each event file in the input resources directory:\\n- Read the event synthesis, summary, and source articles\\n- Group events into thematic blocks (e.g. \"International\", \"Technology\", \"Economy\")\\n- For each event, create a recap with:\\n  - headline: concise, informative (max {max_headline_chars} characters)\\n  - body: factual informative description of the event\\n  - sources: list of original article titles with URLs (for reader reference)\\n\\nBalance the digest:\\n- Don\\'t let one dominant event overshadow the rest\\n- Include variety across themes\\n- Order themes by significance/interest\\n\\nUser preferences:\\n{preferences}\\n\\nOutput format: write a JSON object with \"theme_blocks\" array to output_result_path.\\nEach theme_block has: theme, recaps[]. Each recap has: headline, body, sources[].\\nAlso include a \"meta\" object with: total_events, total_themes, date.\\n' + _FILE_IO_RULES\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_ENRICH_FULL_PROMPT <code>module-attribute</code> <pre><code>RECAP_ENRICH_FULL_PROMPT = 'You are enriching articles from significant news events with full-text content.\\n\\nFor each article file in the input resources directory:\\n- Read the full article content (fetched from the original source URL)\\n- Rewrite the title to be informative and factual\\n- Clean and structure the full text: remove boilerplate, preserve all factual details\\n- This is the deep enrichment pass \u2014 capture as much factual information as possible\\n\\nOutput format: write a JSON object with an \"enriched\" array to output_result_path.\\nEach item must have: article_id, new_title, clean_text.\\n' + _FILE_IO_RULES\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_ENRICH_PROMPT <code>module-attribute</code> <pre><code>RECAP_ENRICH_PROMPT = 'You are processing news articles to prepare them for a digest.\\n\\nFor each article file in the input resources directory:\\n- Read the article content (title, url, text)\\n- Rewrite the title to be informative and factual (not clickbait)\\n- Clean the article text: remove boilerplate, ads, navigation fragments\\n- Preserve all unique factual information\\n\\nOutput format: write a JSON object with an \"enriched\" array to output_result_path.\\nEach item must have: article_id, new_title, clean_text.\\n' + _FILE_IO_RULES\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_GROUP_PROMPT <code>module-attribute</code> <pre><code>RECAP_GROUP_PROMPT = 'You are grouping news articles into real-world events for a daily digest.\\n\\nArticles are provided in articles_index. Each article has: source_id, title, url, source.\\nSome articles may also have enriched text available in the input resources.\\n\\nYour task:\\n1. Identify distinct real-world events that multiple articles cover\\n2. Group articles by event \u2014 an article can belong to exactly one event\\n3. Assign significance: \"high\" for major breaking news, \"medium\" for noteworthy,\\n   \"low\" for minor/local\\n4. Articles that don\\'t fit any event should be grouped as single-article events\\n\\nImportant: limit events to the most informative articles. For dominant events\\n(e.g. a major conflict), include no more than 10 of the most informative articles.\\n\\nOutput format: write a JSON object with an \"events\" array to output_result_path.\\nEach event must have: event_id, title, significance, article_ids, topic_tags.\\n' + _FILE_IO_RULES\n</code></pre> <code></code> news_recap.recap.prompts.RECAP_SYNTHESIZE_PROMPT <code>module-attribute</code> <pre><code>RECAP_SYNTHESIZE_PROMPT = 'You are synthesizing news events from multiple source articles.\\n\\nFor each event file in the input resources directory:\\n- Read all articles belonging to this event\\n- Build a single INFORMATIVE narrative that combines all sources WITHOUT repetition\\n- Preserve unique details from each source\\n- The synthesis must be FACTUAL and INFORMATIVE \u2014 not literary or flowery\\n- If original sources are overly literary, extract the facts and present them clearly\\n- Create a 2-3 sentence summary and a list of key facts\\n\\nWrite one output file per event to output_results_dir: event_{{event_id}}.json\\nEach file must have: event_id, synthesis, summary, key_facts, sources_used.\\n\\nAlso write a summary to output_result_path:\\n{{\"status\": \"completed\", \"processed\": &lt;number of events&gt;}}\\n' + _FILE_IO_RULES\n</code></pre>"},{"location":"reference/#news_recap.recap.resource_loader","title":"news_recap.recap.resource_loader","text":"<p>Resource loader for recap pipeline \u2014 wraps shared HTTP module.</p> Attributes news_recap.recap.resource_loader.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.recap.resource_loader.LoadedResource <code>dataclass</code> <p>Result of loading and extracting content from a URL.</p> Attributes <code></code> news_recap.recap.resource_loader.LoadedResource.content_type <code>instance-attribute</code> <pre><code>content_type: str\n</code></pre> <code></code> news_recap.recap.resource_loader.LoadedResource.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.recap.resource_loader.LoadedResource.is_success <code>instance-attribute</code> <pre><code>is_success: bool\n</code></pre> <code></code> news_recap.recap.resource_loader.LoadedResource.text <code>instance-attribute</code> <pre><code>text: str\n</code></pre> <code></code> news_recap.recap.resource_loader.LoadedResource.url <code>instance-attribute</code> <pre><code>url: str\n</code></pre> <code></code> news_recap.recap.resource_loader.ResourceLoader <p>Load and extract text content from article URLs.</p> <p>Handles both regular web pages (via HTML extraction) and YouTube videos (via subtitle/transcript extraction). Uses the shared http module.</p> Functions <code></code> news_recap.recap.resource_loader.ResourceLoader.close <pre><code>close() -&gt; None\n</code></pre> <code></code> news_recap.recap.resource_loader.ResourceLoader.load <pre><code>load(url: str) -&gt; LoadedResource\n</code></pre> <p>Load content from a URL, auto-detecting YouTube vs HTML.</p> Functions"},{"location":"reference/#news_recap.recap.runner","title":"news_recap.recap.runner","text":"<p>Data-transformation helpers and shared types for the recap pipeline.</p> <p>Business logic (article parsing, event building, etc.) used by <code>prefect_flow.py</code>.  The legacy <code>RecapPipelineRunner</code> class that previously lived here has been removed \u2014 all orchestration now goes through Prefect.</p> Attributes <code></code> news_recap.recap.runner.MIN_ARTICLES_FOR_SIGNIFICANT_EVENT <code>module-attribute</code> <pre><code>MIN_ARTICLES_FOR_SIGNIFICANT_EVENT = 2\n</code></pre> <code></code> news_recap.recap.runner.logger <code>module-attribute</code> <pre><code>logger = getLogger(__name__)\n</code></pre> Classes <code></code> news_recap.recap.runner.PipelineRunResult <code>dataclass</code> <p>Result of a complete pipeline run.</p> Attributes <code></code> news_recap.recap.runner.PipelineRunResult.business_date <code>instance-attribute</code> <pre><code>business_date: date\n</code></pre> <code></code> news_recap.recap.runner.PipelineRunResult.digest <code>class-attribute</code> <code>instance-attribute</code> <pre><code>digest: dict[str, Any] | None = None\n</code></pre> <code></code> news_recap.recap.runner.PipelineRunResult.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.recap.runner.PipelineRunResult.pipeline_id <code>instance-attribute</code> <pre><code>pipeline_id: str\n</code></pre> <code></code> news_recap.recap.runner.PipelineRunResult.status <code>class-attribute</code> <code>instance-attribute</code> <pre><code>status: str = 'running'\n</code></pre> <code></code> news_recap.recap.runner.PipelineRunResult.steps <code>class-attribute</code> <code>instance-attribute</code> <pre><code>steps: list[PipelineStepResult] = field(default_factory=list)\n</code></pre> <code></code> news_recap.recap.runner.PipelineStepResult <code>dataclass</code> <p>Result of a single pipeline step.</p> Attributes <code></code> news_recap.recap.runner.PipelineStepResult.error <code>class-attribute</code> <code>instance-attribute</code> <pre><code>error: str | None = None\n</code></pre> <code></code> news_recap.recap.runner.PipelineStepResult.status <code>instance-attribute</code> <pre><code>status: str\n</code></pre> <code></code> news_recap.recap.runner.PipelineStepResult.step_name <code>instance-attribute</code> <pre><code>step_name: str\n</code></pre> <code></code> news_recap.recap.runner.PipelineStepResult.task_id <code>instance-attribute</code> <pre><code>task_id: str | None\n</code></pre> <code></code> news_recap.recap.runner.RecapPipelineError <p>               Bases: <code>RuntimeError</code></p> <p>Pipeline step failure.</p> Attributes <code></code> news_recap.recap.runner.RecapPipelineError.step <code>instance-attribute</code> <pre><code>step = step\n</code></pre> <code></code> news_recap.recap.runner.UserPreferences <code>dataclass</code> <p>User preferences for digest composition.</p> Attributes <code></code> news_recap.recap.runner.UserPreferences.interesting <code>class-attribute</code> <code>instance-attribute</code> <pre><code>interesting: str = _DEFAULT_INTERESTING\n</code></pre> <code></code> news_recap.recap.runner.UserPreferences.language <code>class-attribute</code> <code>instance-attribute</code> <pre><code>language: str = 'ru'\n</code></pre> <code></code> news_recap.recap.runner.UserPreferences.max_headline_chars <code>class-attribute</code> <code>instance-attribute</code> <pre><code>max_headline_chars: int = 120\n</code></pre> <code></code> news_recap.recap.runner.UserPreferences.not_interesting <code>class-attribute</code> <code>instance-attribute</code> <pre><code>not_interesting: str = _DEFAULT_NOT_INTERESTING\n</code></pre> Functions <code></code> news_recap.recap.runner.UserPreferences.format_for_prompt <pre><code>format_for_prompt() -&gt; str\n</code></pre> Functions <code></code> news_recap.recap.runner.articles_needing_full_text <pre><code>articles_needing_full_text(events: list[dict[str, Any]], article_map: dict[str, ArticleIndexEntry]) -&gt; list[ArticleIndexEntry]\n</code></pre> <p>Collect unique articles from significant events for full-text loading.</p> <code></code> news_recap.recap.runner.articles_to_individual_files <pre><code>articles_to_individual_files(entries: list[SourceCorpusEntry]) -&gt; dict[str, bytes | str]\n</code></pre> <p>One <code>{id}_in.txt</code> per article containing only the headline.</p> <code></code> news_recap.recap.runner.build_event_payloads <pre><code>build_event_payloads(events: list[dict[str, Any]], enriched: dict[str, dict[str, str]], enriched_full: dict[str, dict[str, str]], article_map: dict[str, ArticleIndexEntry]) -&gt; list[dict[str, Any]]\n</code></pre> <p>Merge enriched texts into event payloads for synthesis.</p> <code></code> news_recap.recap.runner.build_routing_defaults <pre><code>build_routing_defaults(settings: Settings) -&gt; RoutingDefaults\n</code></pre> <p>Build RoutingDefaults from Settings for the recap pipeline.</p> <code></code> news_recap.recap.runner.events_to_resource_files <pre><code>events_to_resource_files(events: list[dict[str, Any]]) -&gt; dict[str, bytes | str]\n</code></pre> <p>Serialize events as individual JSON files for LLM input.</p> <code></code> news_recap.recap.runner.merge_enriched_into_index <pre><code>merge_enriched_into_index(entries: list[ArticleIndexEntry], enriched: dict[str, dict[str, str]]) -&gt; list[ArticleIndexEntry]\n</code></pre> <p>Update article titles from enrichment pass.</p> <code></code> news_recap.recap.runner.parse_classify_out_files <pre><code>parse_classify_out_files(results_dir: Path, entries: list[SourceCorpusEntry]) -&gt; tuple[list[str], list[str]]\n</code></pre> <p>Read <code>{id}_out.txt</code> files written by the agent.</p> <p>Each file contains a single word: <code>ok</code>, <code>enrich</code>, or <code>trash</code>. Returns (kept_ids, enrich_ids).  <code>ok</code> and <code>enrich</code> are both kept.</p> <code></code> news_recap.recap.runner.parse_enrich_result <pre><code>parse_enrich_result(payload: dict[str, Any]) -&gt; dict[str, dict[str, str]]\n</code></pre> <p>Return {article_id: {new_title, clean_text}} from enrich output.</p> <code></code> news_recap.recap.runner.parse_group_result <pre><code>parse_group_result(payload: dict[str, Any]) -&gt; list[dict[str, Any]]\n</code></pre> <p>Return events list from group output.</p> <code></code> news_recap.recap.runner.select_significant_events <pre><code>select_significant_events(events: list[dict[str, Any]]) -&gt; list[dict[str, Any]]\n</code></pre> <p>Filter events to only significant ones (high/medium significance or multi-article).</p> <code></code> news_recap.recap.runner.to_article_index <pre><code>to_article_index(entries: list[SourceCorpusEntry]) -&gt; list[ArticleIndexEntry]\n</code></pre>"},{"location":"reference/#news_recap.recap.schemas","title":"news_recap.recap.schemas","text":"<p>I/O JSON schemas (as hint strings) for each recap pipeline step.</p> Attributes news_recap.recap.schemas.RECAP_CLASSIFY_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_CLASSIFY_OUTPUT_SCHEMA = '{\\n  \"status\": \"done\"\\n}\\n\\nActual per-article verdicts go into output_results_dir as {id}_out.txt files,\\neach containing exactly one word: ok, enrich, or trash.'\n</code></pre> <code></code> news_recap.recap.schemas.RECAP_COMPOSE_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_COMPOSE_OUTPUT_SCHEMA = '{\\n  \"theme_blocks\": [\\n    {\\n      \"theme\": \"&lt;thematic group name, e.g. \\'Ukraine conflict\\'&gt;\",\\n      \"recaps\": [\\n        {\\n          \"headline\": \"&lt;concise informative headline&gt;\",\\n          \"body\": \"&lt;informative event description, factual not literary&gt;\",\\n          \"sources\": [\\n            {\\n              \"title\": \"&lt;original article title&gt;\",\\n              \"url\": \"&lt;original article URL&gt;\"\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  ],\\n  \"meta\": {\\n    \"total_events\": &lt;N&gt;,\\n    \"total_themes\": &lt;N&gt;,\\n    \"date\": \"&lt;YYYY-MM-DD&gt;\"\\n  }\\n}'\n</code></pre> <code></code> news_recap.recap.schemas.RECAP_ENRICH_FULL_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_ENRICH_FULL_OUTPUT_SCHEMA = RECAP_ENRICH_OUTPUT_SCHEMA\n</code></pre> <code></code> news_recap.recap.schemas.RECAP_ENRICH_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_ENRICH_OUTPUT_SCHEMA = '{\\n  \"enriched\": [\\n    {\\n      \"article_id\": \"&lt;source_id&gt;\",\\n      \"new_title\": \"&lt;informative headline rewritten from source&gt;\",\\n      \"clean_text\": \"&lt;cleaned and de-duplicated article body&gt;\"\\n    }\\n  ]\\n}'\n</code></pre> <code></code> news_recap.recap.schemas.RECAP_GROUP_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_GROUP_OUTPUT_SCHEMA = '{\\n  \"events\": [\\n    {\\n      \"event_id\": \"&lt;generated unique id, e.g. evt_001&gt;\",\\n      \"title\": \"&lt;descriptive event headline&gt;\",\\n      \"significance\": \"high\" | \"medium\" | \"low\",\\n      \"article_ids\": [\"&lt;source_id&gt;\", \"...\"],\\n      \"topic_tags\": [\"&lt;tag1&gt;\", \"...\"]\\n    }\\n  ]\\n}'\n</code></pre> <code></code> news_recap.recap.schemas.RECAP_SYNTHESIZE_OUTPUT_SCHEMA <code>module-attribute</code> <pre><code>RECAP_SYNTHESIZE_OUTPUT_SCHEMA = '{\\n  \"status\": \"completed\",\\n  \"processed\": &lt;number of events processed&gt;\\n}\\n\\nAdditionally, write one JSON file per event to output_results_dir:\\n\\nevent_{event_id}.json:\\n{\\n  \"event_id\": \"&lt;id&gt;\",\\n  \"synthesis\": \"&lt;informative factual narrative combining all sources&gt;\",\\n  \"summary\": \"&lt;2-3 sentence overview&gt;\",\\n  \"key_facts\": [\"&lt;fact1&gt;\", \"...\"],\\n  \"sources_used\": [\"&lt;article_id&gt;\", \"...\"]\\n}'\n</code></pre> <code></code> news_recap.recap.schemas.SCHEMAS_BY_TASK_TYPE <code>module-attribute</code> <pre><code>SCHEMAS_BY_TASK_TYPE: dict[str, str] = {'recap_classify': RECAP_CLASSIFY_OUTPUT_SCHEMA, 'recap_enrich': RECAP_ENRICH_OUTPUT_SCHEMA, 'recap_group': RECAP_GROUP_OUTPUT_SCHEMA, 'recap_enrich_full': RECAP_ENRICH_FULL_OUTPUT_SCHEMA, 'recap_synthesize': RECAP_SYNTHESIZE_OUTPUT_SCHEMA, 'recap_compose': RECAP_COMPOSE_OUTPUT_SCHEMA}\n</code></pre>"}]}